{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangHungLN/MachineLearning_Assignment/blob/main/Extended_Assignment/notebooks/Extended_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dRutvNf1zS0l",
        "outputId": "ed364c63-8a76-41e3-a89f-3ae45c0ad56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-10 08:56:55--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27164412 (26M) [text/plain]\n",
            "Saving to: ‘data/train.json’\n",
            "\n",
            "data/train.json     100%[===================>]  25.91M   161MB/s    in 0.2s    \n",
            "\n",
            "2025-11-10 08:56:55 (161 MB/s) - ‘data/train.json’ saved [27164412/27164412]\n",
            "\n",
            "--2025-11-10 08:56:55--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3915073 (3.7M) [text/plain]\n",
            "Saving to: ‘data/dev.json’\n",
            "\n",
            "data/dev.json       100%[===================>]   3.73M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-11-10 08:56:56 (50.9 MB/s) - ‘data/dev.json’ saved [3915073/3915073]\n",
            "\n",
            "--2025-11-10 08:56:56--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/forward_algorithm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1590 (1.6K) [text/plain]\n",
            "Saving to: ‘modules/forward_algorithm.py’\n",
            "\n",
            "modules/forward_alg 100%[===================>]   1.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-10 08:56:56 (24.2 MB/s) - ‘modules/forward_algorithm.py’ saved [1590/1590]\n",
            "\n",
            "--2025-11-10 08:56:56--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/viterbi_algorithm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2713 (2.6K) [text/plain]\n",
            "Saving to: ‘modules/viterbi_algorithm.py’\n",
            "\n",
            "modules/viterbi_alg 100%[===================>]   2.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-10 08:56:56 (54.6 MB/s) - ‘modules/viterbi_algorithm.py’ saved [2713/2713]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import json\n",
        "import os\n",
        "import getpass, os, subprocess, textwrap\n",
        "\n",
        "\n",
        "os.makedirs(\"data\", exist_ok = True)\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/train.json -O data/train.json\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/dev.json -O data/dev.json\n",
        "os.makedirs(\"modules\", exist_ok= True)\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/forward_algorithm.py -O modules/forward_algorithm.py\n",
        "!wget  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/viterbi_algorithm.py -O modules/viterbi_algorithm.py\n",
        "\n",
        "DATA_FILE = 'data/train.json'\n",
        "DEV_FILE = 'data/dev.json'\n",
        "PARAM_DIR = 'Extended_Assigment/parameters'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(DATA_FILE, 'r', encoding='utf-8') as f:\n",
        "    raw_train = json.load(f)\n",
        "with open(DEV_FILE, 'r', encoding='utf-8') as f:\n",
        "    raw_dev = json.load(f)\n",
        "\n",
        "TAG_KEY = \"labels\"\n",
        "\n",
        "X_train = [ex['sentence'] for ex in raw_train]\n",
        "Y_train = [ex[TAG_KEY]     for ex in raw_train]\n",
        "X_dev   = [ex['sentence'] for ex in raw_dev]\n",
        "Y_dev   = [ex[TAG_KEY]     for ex in raw_dev]"
      ],
      "metadata": {
        "id": "vfN130uH_WTx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNK = \"<UNK>\"\n",
        "min_freq = 1\n",
        "\n",
        "word_freq = Counter(w for sent in X_train for w in sent)\n",
        "vocab = {w for w,c in word_freq.items() if c > min_freq}\n",
        "vocab.add(UNK)\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "tag_set = sorted({t for tags in Y_train for t in tags})\n",
        "\n",
        "word2id = {w:i for i,w in enumerate(vocab)}\n",
        "tag2id  = {t:i for i,t in enumerate(tag_set)}\n",
        "id2tag  = {i:t for t,i in tag2id.items()}\n",
        "\n",
        "def map_unk(sent):\n",
        "    return [w if w in word2id else UNK for w in sent]\n",
        "\n",
        "X_train = [map_unk(s) for s in X_train]\n",
        "X_dev   = [map_unk(s) for s in X_dev]"
      ],
      "metadata": {
        "id": "t_VNNWm4_rJb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def estimate_hmm_supervised(X, Y, tag2id, word2id,\n",
        "                            alpha_pi=1.0, alpha_A=1.0, alpha_B=1e-3):\n",
        "    K, V = len(tag2id), len(word2id)\n",
        "    pi_cnt = np.full(K,     alpha_pi, dtype=np.float64)\n",
        "    A_cnt  = np.full((K,K), alpha_A,  dtype=np.float64)\n",
        "    B_cnt  = np.full((K,V), alpha_B,  dtype=np.float64)\n",
        "\n",
        "    for words, tags in zip(X, Y):\n",
        "        if not words:\n",
        "            continue\n",
        "        pi_cnt[tag2id[tags[0]]] += 1\n",
        "        for t in range(len(words)):\n",
        "            j = tag2id[tags[t]]\n",
        "            w = word2id[words[t]]\n",
        "            B_cnt[j, w] += 1\n",
        "            if t < len(words)-1:\n",
        "                i = tag2id[tags[t]]\n",
        "                k = tag2id[tags[t+1]]\n",
        "                A_cnt[i, k] += 1\n",
        "\n",
        "    pi = pi_cnt / pi_cnt.sum()\n",
        "    A  = A_cnt / A_cnt.sum(axis=1, keepdims=True)\n",
        "    B  = B_cnt / B_cnt.sum(axis=1, keepdims=True)\n",
        "    return pi, A, B\n",
        "\n",
        "pi, A, B = estimate_hmm_supervised(X_train, Y_train, tag2id, word2id)"
      ],
      "metadata": {
        "id": "Lh4UDXq9_7cA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(PARAM_DIR, exist_ok=True)\n",
        "\n",
        "np.savez_compressed(\n",
        "    os.path.join(PARAM_DIR, \"hmm_params_supervised.npz\"),\n",
        "    pi=pi, A=A, B=B\n",
        ")\n",
        "\n",
        "config = {\n",
        "    \"UNK\": UNK,\n",
        "    \"tag_key\": TAG_KEY,\n",
        "    \"vocab\":   vocab,      # giữ nguyên thứ tự tương ứng với ma trận B\n",
        "    \"tag_set\": tag_set,    # giữ nguyên thứ tự tương ứng với các ma trận\n",
        "    \"alpha\": {\"pi\":1.0, \"A\":1.0, \"B\":1e-3}\n",
        "}\n",
        "with open(os.path.join(PARAM_DIR, \"tag_word_maps.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(config, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved files:\", os.listdir(PARAM_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTDxjXpUBPPa",
        "outputId": "9b23cc73-ceb0-4ef5-a231-be20dd07a8a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved files: ['hmm_params_supervised.npz', 'tag_word_maps.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.forward_algorithm import *\n",
        "\n",
        "print(\"\\n--- Đang chạy thử Giải thuật Forward ---\")\n",
        "\n",
        "# Chúng ta KHÔNG CẦN TẢI LẠI (load) các file đã lưu,\n",
        "# vì các biến `pi`, `A`, `B`, `X_dev`, `word2id` đã có sẵn trong bộ nhớ.\n",
        "\n",
        "# 2.1. Lấy một câu từ tập dev để làm chuỗi quan sát (O)\n",
        "# (Lưu ý: `X_dev` đã được map_unk ở trên)\n",
        "test_sentence_words = X_dev[1]  # Lấy câu thứ 2 từ tập dev\n",
        "print(f\"Câu kiểm tra: {' '.join(test_sentence_words)}\")\n",
        "\n",
        "# 2.2. Chuyển câu (words) sang chuỗi quan sát O (indices)\n",
        "O_indices = []\n",
        "idx_unk = word2id[UNK] # Lấy chỉ số của token UNK\n",
        "for word in test_sentence_words:\n",
        "    # Lấy chỉ số, nếu không có thì dùng chỉ số UNK\n",
        "    idx = word2id.get(word, idx_unk)\n",
        "    O_indices.append(idx)\n",
        "O_indices = np.array(O_indices)\n",
        "\n",
        "print(f\"Chuỗi quan sát (O) dạng chỉ số: {O_indices[:15]}...\")\n",
        "\n",
        "# 2.3. Gọi hàm forward\n",
        "if len(O_indices) > 0:\n",
        "    total_prob = forward_algorithm(O_indices, pi, A, B)\n",
        "    print(\"\\n--- Kết quả Forward ---\")\n",
        "    print(f\"Tổng xác suất P(O|lambda): {total_prob}\")\n",
        "else:\n",
        "    print(\"Câu kiểm tra bị rỗng, không thể chạy Forward.\")"
      ],
      "metadata": {
        "id": "Gp_d_e9NZncz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2081241e-e2d3-4adb-f0ea-f736606e834a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Đang chạy thử Giải thuật Forward ---\n",
            "Câu kiểm tra: The ruling follows a host of problems at Tucson Electric , including major write-downs , a 60 % slash in the common stock dividend and the departure of former Chairman <UNK> <UNK> during a company investigation of his stock sales .\n",
            "Chuỗi quan sát (O) dạng chỉ số: [ 8317 19895 14149  9067 15087 17426 18590  9880  8521  3942    26 15329\n",
            " 16460 23114    26]...\n",
            "\n",
            "--- Kết quả Forward ---\n",
            "Tổng xác suất P(O|lambda): 9.834108917689142e-108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Giới thiệu các nhãn POS (Penn Treebank)\n",
        "\n",
        "Trong bài này, em dataset nhóm sử dụng bộ nhãn POS theo chuẩn **Penn Treebank**. Dưới đây là một số nhãn thường gặp:\n",
        "\n",
        "### 1. Danh từ (Nouns)\n",
        "\n",
        "| Tag   | Ý nghĩa                               | Ví dụ                        |\n",
        "|-------|---------------------------------------|------------------------------|\n",
        "| **NN**   | Danh từ thường, số ít                  | dog, house, book             |\n",
        "| **NNS**  | Danh từ thường, số nhiều               | dogs, houses, books          |\n",
        "| **NNP**  | Danh từ riêng, số ít                   | John, London, Tuesday        |\n",
        "| **NNPS** | Danh từ riêng, số nhiều                | Americans, Europeans         |\n",
        "\n",
        "### 2. Động từ (Verbs)\n",
        "\n",
        "| Tag   | Ý nghĩa                                             | Ví dụ                              |\n",
        "|-------|-----------------------------------------------------|------------------------------------|\n",
        "| **VB**   | Động từ nguyên mẫu                                | eat, go, run                       |\n",
        "| **VBD**  | Động từ quá khứ                                  | ate, went, ran                     |\n",
        "| **VBG**  | Hiện tại phân từ / V-ing                         | eating, going, running            |\n",
        "| **VBN**  | Quá khứ phân từ                                  | eaten, gone, broken               |\n",
        "| **VBP**  | Hiện tại, không ngôi thứ 3 số ít                 | I eat, you go                      |\n",
        "| **VBZ**  | Hiện tại, ngôi thứ 3 số ít                       | he eats, she goes                 |\n",
        "\n",
        "### 3. Tính từ & Trạng từ\n",
        "\n",
        "| Tag   | Ý nghĩa                         | Ví dụ                         |\n",
        "|-------|---------------------------------|-------------------------------|\n",
        "| **JJ**   | Tính từ                         | big, small, happy             |\n",
        "| **JJR**  | Tính từ so sánh hơn             | bigger, smaller, happier      |\n",
        "| **JJS**  | Tính từ so sánh nhất            | biggest, smallest, happiest   |\n",
        "| **RB**   | Trạng từ                        | quickly, very, well           |\n",
        "| **RBR**  | Trạng từ so sánh hơn            | faster, better                |\n",
        "| **RBS**  | Trạng từ so sánh nhất           | fastest, best                 |\n",
        "\n",
        "### 4. Đại từ, mạo từ, giới từ, liên từ\n",
        "\n",
        "| Tag    | Ý nghĩa                           | Ví dụ                         |\n",
        "|--------|-----------------------------------|--------------------------------|\n",
        "| **PRP**   | Đại từ nhân xưng                  | I, you, he, she, they          |\n",
        "| **PRP$**  | Đại từ sở hữu                     | my, your, his, her             |\n",
        "| **DT**    | Mạo từ / từ hạn định              | a, an, the, this, those        |\n",
        "| **IN**    | Giới từ / liên từ phụ thuộc       | in, on, at, of, because, if    |\n",
        "| **CC**    | Liên từ đẳng lập                  | and, or, but                   |\n",
        "| **TO**    | Từ *to* (trước động từ nguyên mẫu) | to go, to eat                  |\n",
        "\n",
        "### 5. Một số nhãn khác\n",
        "\n",
        "| Tag   | Ý nghĩa                     | Ví dụ                       |\n",
        "|-------|-----------------------------|-----------------------------|\n",
        "| **MD**   | Trợ động từ khuyết thiếu    | can, will, must, should     |\n",
        "| **CD**   | Số từ                      |  10, 20       |\n",
        "| **UH**   | Thán từ                    | oh,              |\n",
        "| **. , : ; ? !** | Dấu câu            | . , : ; ? !                 |\n",
        "\n",
        "Trong mô hình HMM, các nhãn POS ở trên chính là **trạng thái ẩn**, còn các từ trong câu là **chuỗi quan sát**. Nhiệm vụ của mô hình là, với mỗi câu đầu vào, tìm ra chuỗi nhãn POS phù hợp nhất cho từng từ.\n"
      ],
      "metadata": {
        "id": "k2IDLzZRzNFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = tag_set\n",
        "\n",
        "# 4. Chuyển pi, A, B từ array sang dict mà hàm viterbi cần\n",
        "start_p = {\n",
        "    tag: float(pi[i])\n",
        "    for i, tag in enumerate(tag_set)\n",
        "}\n",
        "\n",
        "trans_p = {\n",
        "    tag_i: {\n",
        "        tag_j: float(A[i, j])\n",
        "        for j, tag_j in enumerate(tag_set)\n",
        "    }\n",
        "    for i, tag_i in enumerate(tag_set)\n",
        "}\n",
        "\n",
        "emit_p = {\n",
        "    tag_i: {\n",
        "        word: float(B[i, w])\n",
        "        for w, word in enumerate(vocab)\n",
        "    }\n",
        "    for i, tag_i in enumerate(tag_set)\n",
        "}"
      ],
      "metadata": {
        "id": "4q30LI_Zf6UI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.viterbi_algorithm import *\n",
        "test_words = X_dev[1]\n",
        "gold_tags  = Y_dev[1]\n",
        "\n",
        "pred_tags, prob = viterbi_algorithm(test_words, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu test:\")\n",
        "print(test_words)\n",
        "print(\"\\nNhãn dự đoán:\")\n",
        "print(pred_tags)\n",
        "print(\"\\nNhãn gold:\")\n",
        "print(gold_tags)\n",
        "print(\"\\nXác suất:\", prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO1pyqOTgFhb",
        "outputId": "d706a09c-e338-4bed-de2f-3f6b4dfdc7d9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu test:\n",
            "['The', 'ruling', 'follows', 'a', 'host', 'of', 'problems', 'at', 'Tucson', 'Electric', ',', 'including', 'major', 'write-downs', ',', 'a', '60', '%', 'slash', 'in', 'the', 'common', 'stock', 'dividend', 'and', 'the', 'departure', 'of', 'former', 'Chairman', '<UNK>', '<UNK>', 'during', 'a', 'company', 'investigation', 'of', 'his', 'stock', 'sales', '.']\n",
            "\n",
            "Nhãn dự đoán:\n",
            "['DT', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'NNS', 'IN', 'NNP', 'NNP', ',', 'VBG', 'JJ', 'NNS', ',', 'DT', 'CD', 'NN', 'VB', 'IN', 'DT', 'JJ', 'NN', 'NN', 'CC', 'DT', 'NN', 'IN', 'JJ', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'NN', 'IN', 'PRP$', 'NN', 'NNS', '.']\n",
            "\n",
            "Nhãn gold:\n",
            "['DT', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'NNS', 'IN', 'NNP', 'NNP', ',', 'VBG', 'JJ', 'NNS', ',', 'DT', 'CD', 'NN', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NN', 'CC', 'DT', 'NN', 'IN', 'JJ', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'NN', 'IN', 'PRP$', 'NN', 'NNS', '.']\n",
            "\n",
            "Xác suất: 1.2834557554191526e-108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ed9WSxpaZpW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_sent1 = [\"he\", \"loves\" \"this\", \"subject\", \"the\", \"most\"]\n",
        "test_words1 = map_unk(raw_sent1)\n",
        "\n",
        "pred_tags1, prob1 = viterbi_algorithm(test_words1, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu gốc:\", raw_sent1)\n",
        "print(\"Câu sau khi map UNK:\", test_words1)\n",
        "print(\"Nhãn dự đoán:\", pred_tags1)\n",
        "print(\"Xác suất:\", prob1)\n",
        "\n",
        "raw_sent2 = [\"he\", \"is\", \"doing\", \"machine\", \"learning\", \"assignment\"]\n",
        "test_words2 = map_unk(raw_sent2)\n",
        "\n",
        "pred_tags2, prob2 = viterbi_algorithm(test_words2, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu gốc:\", raw_sent2)\n",
        "print(\"Câu sau khi map UNK:\", test_words2)\n",
        "print(\"Nhãn dự đoán:\", pred_tags2)\n",
        "print(\"Xác suất:\", prob2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0YpqlQngRJi",
        "outputId": "e79060ce-6987-4104-9c35-565bd12804cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu gốc: ['he', 'lovethis', 'subject', 'the', 'most']\n",
            "Câu sau khi map UNK: ['he', '<UNK>', 'subject', 'the', 'most']\n",
            "Nhãn dự đoán: ['PRP', 'VBZ', 'JJ', 'DT', 'RBS']\n",
            "Xác suất: 1.367787998995333e-14\n",
            "Câu gốc: ['he', 'is', 'doing', 'machine', 'learning', 'assignment']\n",
            "Câu sau khi map UNK: ['he', 'is', 'doing', 'machine', 'learning', 'assignment']\n",
            "Nhãn dự đoán: ['PRP', 'VBZ', 'VBG', 'NN', 'VBG', 'NN']\n",
            "Xác suất: 9.515088851763234e-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khi thử một số câu tự tạo như:\n",
        "\n",
        "- \"he love this subject the most\"\n",
        "- \"he is doing machine learning assignment\"\n",
        "\n",
        "mô hình gán nhãn khá hợp lý: phân biệt đúng các đại từ (PRP), động từ chia theo chủ ngữ (VBZ), dạng V-ing (VBG), mạo từ (DT), trạng từ so sánh nhất (RBS).\n",
        "\n",
        "Các lỗi chủ yếu xuất hiện ở những cụm mơ hồ như \"machine learning\", nơi từ *learning* vừa có thể được gán là danh từ (NN) vừa có thể là động từ dạng V-ing (VBG). Đây là kiểu mơ hồ thường gặp của mô hình HMM sử dụng ngữ cảnh ngắn.\n"
      ],
      "metadata": {
        "id": "AQagqFH-_vko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "total_tokens  = 0\n",
        "\n",
        "for words, gold in zip(X_dev, Y_dev):\n",
        "    pred, _ = viterbi_algorithm(words, states, start_p, trans_p, emit_p)\n",
        "    # đếm đúng / sai cho câu này\n",
        "    for p, g in zip(pred, gold):\n",
        "        if p == g:\n",
        "            total_correct += 1\n",
        "        total_tokens += 1\n",
        "\n",
        "overall_acc = total_correct / total_tokens\n",
        "print(\"Accuracy toàn dev set:\", overall_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgPV2QGa0joI",
        "outputId": "f7a42ffd-f52b-4037-ffd5-c23ce388792d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy toàn dev set: 0.9482120089854896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nhận xét kết quả**\n",
        "\n",
        "Đoạn code trên tính **độ chính xác (accuracy)** trên tập dev theo công thức:\n",
        "\n",
        "$$\n",
        "\\text{accuracy} = \\frac{\\text{số token gán đúng nhãn}}{\\text{tổng số token}}\n",
        "$$\n",
        "\n",
        "Kết quả thu được:\n",
        "\n",
        "- **Accuracy trên dev ≈ 0.9482 (≈ 94.8%)**\n",
        "\n",
        "Như vậy, với một mô hình HMM rất cơ bản (ước lượng tham số bằng đếm tần suất có smoothing, dùng token `<UNK>` cho từ hiếm) và thuật toán Viterbi, hệ thống đã gán đúng POS cho gần **95% số từ** trong tập kiểm tra. Đây là một kết quả khá tốt đối với HMM thuần túy, cho thấy mô hình đã học được phân bố:\n",
        "\n",
        "- xác suất bắt đầu câu với từng nhãn,\n",
        "- xác suất chuyển tiếp giữa các nhãn (A),\n",
        "- xác suất phát xạ từ ứng với từng nhãn (B).\n",
        "\n",
        "Phần **~5% còn lại** chủ yếu rơi vào các trường hợp mơ hồ về từ loại, ví dụ những từ vừa có thể là danh từ vừa có thể là động từ/tính từ, hoặc các từ ít xuất hiện trong tập huấn luyện. Đây là giới hạn tự nhiên của HMM bậc 1 chỉ dùng thông tin ngữ cảnh rất ngắn (tag ngay trước), chưa tận dụng được ngữ cảnh xa hay thông tin hình thái (suffix, viết hoa, v.v.).\n",
        "\n",
        "Trong các hướng phát triển tiếp theo, có thể cải thiện bằng cách:\n",
        "- thêm đặc trưng cho từ mới (đuôi `-ing`, `-ed`, số nhiều `-s`, chữ hoa…),\n",
        "- dùng mô hình mạnh hơn như BiLSTM-CRF hoặc Transformer-based tagger,"
      ],
      "metadata": {
        "id": "98bDPNqJ-SRo"
      }
    }
  ]
}