{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangHungLN/MachineLearning_Assignment/blob/main/Extended_Assignment/notebooks/Extended_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dRutvNf1zS0l",
        "outputId": "3c54b286-56c1-4f00-f086-a0b9c7635423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-12 14:18:03--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27164412 (26M) [text/plain]\n",
            "Saving to: ‘data/train.json’\n",
            "\n",
            "\rdata/train.json       0%[                    ]       0  --.-KB/s               \rdata/train.json     100%[===================>]  25.91M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-12 14:18:03 (271 MB/s) - ‘data/train.json’ saved [27164412/27164412]\n",
            "\n",
            "--2025-11-12 14:18:03--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3915073 (3.7M) [text/plain]\n",
            "Saving to: ‘data/dev.json’\n",
            "\n",
            "data/dev.json       100%[===================>]   3.73M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-11-12 14:18:03 (89.4 MB/s) - ‘data/dev.json’ saved [3915073/3915073]\n",
            "\n",
            "--2025-11-12 14:18:03--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/forward_algorithm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1590 (1.6K) [text/plain]\n",
            "Saving to: ‘modules/forward_algorithm.py’\n",
            "\n",
            "modules/forward_alg 100%[===================>]   1.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-12 14:18:03 (36.3 MB/s) - ‘modules/forward_algorithm.py’ saved [1590/1590]\n",
            "\n",
            "--2025-11-12 14:18:03--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/viterbi_algorithm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2713 (2.6K) [text/plain]\n",
            "Saving to: ‘modules/viterbi_algorithm.py’\n",
            "\n",
            "modules/viterbi_alg 100%[===================>]   2.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-12 14:18:03 (30.4 MB/s) - ‘modules/viterbi_algorithm.py’ saved [2713/2713]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import getpass, os, subprocess, textwrap\n",
        "\n",
        "os.makedirs(\"data\", exist_ok = True)\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/train.json -O data/train.json\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/dev.json -O data/dev.json\n",
        "os.makedirs(\"modules\", exist_ok= True)\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/forward_algorithm.py -O modules/forward_algorithm.py\n",
        "!wget  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/viterbi_algorithm.py -O modules/viterbi_algorithm.py\n",
        "\n",
        "DATA_FILE = 'data/train.json'\n",
        "DEV_FILE = 'data/dev.json'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(DATA_FILE, 'r', encoding='utf-8') as f:\n",
        "    raw_train = json.load(f)\n",
        "with open(DEV_FILE, 'r', encoding='utf-8') as f:\n",
        "    raw_dev = json.load(f)\n",
        "\n",
        "X_train = [ex['sentence'] for ex in raw_train]\n",
        "Y_train = [ex['labels']     for ex in raw_train]\n",
        "X_dev   = [ex['sentence'] for ex in raw_dev]\n",
        "Y_dev   = [ex['labels']     for ex in raw_dev]"
      ],
      "metadata": {
        "id": "vfN130uH_WTx"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNK = \"<UNK>\"\n",
        "min_freq = 1\n",
        "\n",
        "word_freq = Counter(w for sent in X_train for w in sent)\n",
        "vocab = {w for w,c in word_freq.items() if c > min_freq}\n",
        "vocab.add(UNK)\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "tag_set = sorted({t for tags in Y_train for t in tags})\n",
        "\n",
        "word2id = {w:i for i,w in enumerate(vocab)}\n",
        "tag2id  = {t:i for i,t in enumerate(tag_set)}\n",
        "id2tag  = {i:t for t,i in tag2id.items()}\n",
        "\n",
        "def map_unk(sent):\n",
        "    return [w if w in word2id else UNK for w in sent]\n",
        "\n",
        "X_train = [map_unk(s) for s in X_train]\n",
        "X_dev   = [map_unk(s) for s in X_dev]"
      ],
      "metadata": {
        "id": "t_VNNWm4_rJb"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def estimate_hmm_supervised(X, Y, tag2id, word2id,\n",
        "                            alpha_pi=1.0, alpha_A=1.0, alpha_B=1e-3):\n",
        "    K, V = len(tag2id), len(word2id)\n",
        "    pi_cnt = np.full(K,     alpha_pi, dtype=np.float64)\n",
        "    A_cnt  = np.full((K,K), alpha_A,  dtype=np.float64)\n",
        "    B_cnt  = np.full((K,V), alpha_B,  dtype=np.float64)\n",
        "\n",
        "    for words, tags in zip(X, Y):\n",
        "        if not words:\n",
        "            continue\n",
        "        pi_cnt[tag2id[tags[0]]] += 1\n",
        "        for t in range(len(words)):\n",
        "            j = tag2id[tags[t]]\n",
        "            w = word2id[words[t]]\n",
        "            B_cnt[j, w] += 1\n",
        "            if t < len(words)-1:\n",
        "                i = tag2id[tags[t]]\n",
        "                k = tag2id[tags[t+1]]\n",
        "                A_cnt[i, k] += 1\n",
        "\n",
        "    pi = pi_cnt / pi_cnt.sum()\n",
        "    A  = A_cnt / A_cnt.sum(axis=1, keepdims=True)\n",
        "    B  = B_cnt / B_cnt.sum(axis=1, keepdims=True)\n",
        "    return pi, A, B\n",
        "\n",
        "pi, A, B = estimate_hmm_supervised(X_train, Y_train, tag2id, word2id)"
      ],
      "metadata": {
        "id": "Lh4UDXq9_7cA"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Giải thuật Forward\n"
      ],
      "metadata": {
        "id": "Yo3dXv1nDnN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx_unk = word2id[UNK]\n",
        "results = []\n",
        "for sentence_words in X_dev:\n",
        "    # Bỏ qua câu rỗng (nếu có)\n",
        "    if not sentence_words:\n",
        "        continue\n",
        "\n",
        "    # Chuyển câu sang chuỗi quan sát O (indices)\n",
        "    O_indices = []\n",
        "    for word in sentence_words:\n",
        "        idx = word2id.get(word, idx_unk)\n",
        "        O_indices.append(idx)\n",
        "    O_indices = np.array(O_indices)\n",
        "\n",
        "    prob = forward_algorithm(O_indices, pi, A, B)\n",
        "\n",
        "    results.append( (' '.join(sentence_words), prob) )\n",
        "\n",
        "results.sort(key=lambda x: x[1])\n",
        "\n",
        "print(f\"\\n--- KẾT QUẢ THÍ NGHIỆM FORWARD (trên {len(results)} câu của dev.json) ---\")\n",
        "\n",
        "print(f\"\\n--- 10 CÂU CÓ XÁC SUẤT THẤP NHẤT ---\")\n",
        "# Lấy 10 câu đầu tiên (thấp nhất)\n",
        "for sentence, p in results[:10]:\n",
        "  print(f\"Prob: {p: .2e} | Câu: {sentence}\")\n",
        "\n",
        "print(f\"\\n--- 10 CÂU CÓ XÁC SUẤT CAO NHẤT ---\")\n",
        "# Lấy 10 câu cuối (cao nhất) và lật ngược lại\n",
        "for sentence, p in reversed(results[-10:]):\n",
        "  print(f\"Prob: {p: .2e} | Câu: {sentence}\")"
      ],
      "metadata": {
        "id": "lUcPLRSGIBVa",
        "outputId": "e4bd6b44-d31a-4a19-a3aa-c9081beb5449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- KẾT QUẢ THÍ NGHIỆM FORWARD (trên 5527 câu của dev.json) ---\n",
            "\n",
            "--- 10 CÂU CÓ XÁC SUẤT THẤP NHẤT ---\n",
            "Prob:  1.41e-246 | Câu: <UNK> <UNK> <UNK> , San Francisco , telecommunications holding company , annual sales of $ 9.5 billion , no damage to headquarters , but no power , the power failure has caused a delay in the release of the company 's earnings report , major concern is subsidiaries , Pacific Bell and Pacific Telesis Cellular , both of which sustained damage to buildings , structural damage to several cellular sites in Santa Cruz , volume of calls on cellular phones 10 times the usual , causing a big slowdown .\n",
            "Prob:  3.93e-243 | Câu: Daniel von <UNK> is <UNK> but totally assured as Major Battle , <UNK> just the right brand of <UNK> and <UNK> ; Jeff Weiss is fire , <UNK> and <UNK> <UNK> as the <UNK> senator who serves as a friendly <UNK> of Major Battle ; <UNK> <UNK> is <UNK> <UNK> playing a succession of lawyers ; Joseph Daly has the perfect `` <UNK> , <UNK> '' <UNK> of George Bush in his portrayal of the vice president ; and Ann McDonough is <UNK> as a succession of witnesses ' wives .\n",
            "Prob:  8.83e-243 | Câu: <UNK> <UNK> & <UNK> <UNK> , San Francisco , electric , gas and water supplier , annual sales $ 7.6 billion , some minor damage to headquarters , <UNK> damage to four nearby <UNK> , severe structural damage to a major power plant at Moss <UNK> , extensive damage to gas lines and electric lines , 400,000 <UNK> without electricity and <UNK> without gas , can not <UNK> electricity until it is certain there are no gas leaks , no predictions on when this will happen .\n",
            "Prob:  1.63e-218 | Câu: If , for example , in the midst of a great social occasion ( such as an international conference on revising the <UNK> Treaty in <UNK> ) , one 's <UNK> father , himself a great <UNK> once , should happen to die of a stroke , one must continue to serve the port : `` Please do n't think me unduly improper in not ascending to see my father in his deceased condition just at this moment .\n",
            "Prob:  1.73e-215 | Câu: As he stands on a hill at the beginning of a six-day motor <UNK> from <UNK> to <UNK> , where a former <UNK> <UNK> , perhaps the victim of an unhappy 20-year marriage , perhaps ( he hopes with more <UNK> than he will ever acknowledge ) not <UNK> to return to domestic service , Stevens surveys the view and thereby provides a <UNK> , a <UNK> and the author 's metaphor for the aesthetic of the novel we 're reading :\n",
            "Prob:  5.91e-215 | Câu: But we still hear him <UNK> at night because the Navy has a few ships left , and to satisfy him the Navy 's sea lift forces were given to a new Air Force bureaucracy in Illinois , its space operations to another command in Colorado , the <UNK> to a new Army bureaucracy in Fort <UNK> , and the Navy 's Indian Ocean and Persian Gulf forces to an Army bureaucracy in Florida .\n",
            "Prob:  3.47e-211 | Câu: Mr. <UNK> , a former publisher and real estate developer , has put together an $ 8 million financial package that includes approximately $ 4 million of tax exempt bonds issued by the State of Illinois ( the first time that a state has used its educational facilities authority to support construction of a theater ) , and approximately $ 1 million in grants from the National <UNK> for the Arts , the <UNK> Foundation , and a few other deep pockets .\n",
            "Prob:  3.61e-208 | Câu: The $ 4 billion in bonds break down as follows : $ 1 billion in five-year bonds with a coupon rate of 8.25 % and a yield to maturity of 8.33 % ; $ 1 billion in 10-year bonds with a coupon rate of 8.375 % and a yield to maturity of 8.42 % ; $ 2 billion in 30-year bonds with five-year call protection , a coupon rate of 8.75 % and a yield to maturity of <UNK> % .\n",
            "Prob:  2.10e-196 | Câu: Thus , you do the public a great <UNK> when Mr. <UNK> suggests , even <UNK> , that the Clean Water Act prohibits the preparation of a scotch and water ; your <UNK> readers may be led to believe that nothing but chance or oversight protects them , as they <UNK> in the night with their scotch and waters , from the <UNK> knock of the Sierra Club at their doors .\n",
            "Prob:  5.27e-196 | Câu: In an <UNK> of little <UNK> to his central point about private enforcement suits by environmental groups , Michael S. <UNK> <UNK> your readers , `` ... the Clean Water Act is written upon the presumption -- the <UNK> , rather -- that nothing but zero risk will do ; it establishes a legal standard of zero discharge '' ( `` <UNK> Environmental <UNK> , '' Sept. 18 ) .\n",
            "\n",
            "--- 10 CÂU CÓ XÁC SUẤT CAO NHẤT ---\n",
            "Prob:  1.10e-03 | Câu: <UNK> .\n",
            "Prob:  1.10e-03 | Câu: <UNK> .\n",
            "Prob:  4.70e-04 | Câu: <UNK> <UNK>\n",
            "Prob:  7.24e-05 | Câu: Citicorp\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  9.17e-06 | Câu: White <UNK>\n",
            "Prob:  9.17e-06 | Câu: White <UNK>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phân tích và Đánh giá Kết quả Giải thuật Forward\n",
        "\n",
        "## 1. Các câu có xác suất cao nhất\n",
        "\n",
        "10 câu có xác suất cao nhất đều là các câu cực kỳ ngắn (1-2 từ).Đáng chú ý nhất, các câu có xác suất cao tuyệt đối là \"UNK .\" và \"UNK UNK\".\n",
        "\n",
        "Từ kết quả ta có thể thấy được hiện tượng thiên vị về độ dài. Cụ thể, các câu càng ngắn thì càng có xác suất lớn. Hiện tượng trên là do giải thuật Forward tính xác suất cuối cùng P(O) bằng cách nhân liên tiếp các xác suất tại mỗi bước thời gian.Vì tất cả các xác suất đều nhỏ hơn 1.0, về mặt toán học, câu càng ngắn thì càng ít phép nhân dẫn xác suất cuối cùng càng cao.\n",
        "\n",
        "Bên cạnh đó, sự xuất hiện của UNK, UNK trở thành từ phổ biến nhất trong từ điển do quá trình thay thế từ hiếm với sự xuất hiện ít hơn 2 lần thành UNK, quá trình đó cộng dồn trong quá trình train tham số cho mô hình, dẫn đến UNK vô tình trở thành từ xuất hiện nhiều nhất, dẫn đến xác suất sinh ra UNK tại các trạng thái trở nên lớn hơn.\n",
        "\n",
        "# 2. Các câu có xác suất thấp nhất\n",
        "10 câu có xác suất thấp nhất đều là các câu rất dài (50–70+ từ), và chứa nhiều UNK cùng cấu trúc phức tạp.\n",
        "\n",
        "Đây cũng là kết quả của hiện tượng thiên vị về độ dài, khi các từ có độ dài càng cao thì số lượng phép nhân cho số bé hơn 1 càng nhiều, dẫn đến giá trị xác suất trở nên rất bé.\n",
        "\n",
        "Bên cạnh đó các câu này còn có cấu trúc ngữ pháp phức tạp hơn, khiến cho ma trận chuyển tiếp A chứa các giá trị chuyển trạng thái rất nhỏ khi gặp cấu trúc này.\n",
        "\n",
        "# 3. Giá trị xác suất quá nhỏ\n",
        "Đối với tập dữ liệu hiện tại, các câu có độ dài không quá lớn khiến cho giá trị xác suất không bị bé vượt ngưỡng e-324 của kiểu float64 mà numpy đang sử dụng. Nhưng với giải thuật hiện tại, nếu gặp câu có độ dài lớn hơn nhiều sẽ rất dễ gặp hiện tượng tràn số dưới dẫn đến giá trị xác suất trả về là 0.0. Để giải quyết cho hiện tượng trên, ta hoàn toàn có thể chuyển bài toán sang không gian logagite Bằng cách này, phép nhân xác suất (ví dụ: $P_1 \\times P_2$) được chuyển đổi thành phép cộng log-probability (ví dụ: $\\log(P_1) + \\log(P_2)$), giúp tránh các giá trị bị làm tròn về 0. Khi cần thực hiện phép cộng trong không gian log, kỹ thuật \"Log-Sum-Exp\" sẽ được sử dụng để đảm bảo tính toán luôn ổn định.\n",
        "\n",
        "# Kết quả\n",
        "Mô hình HMM giải thích khá tốt về cấu trúc ngữ pháp cho câu, khi với độ dài nhất định, một câu có xác suất xảy ra cao hơn thì sẽ có cấu trúc ngữ pháp phù hợp hơn trong mô hình đang xét. Tuy nhiên, mô hình vẫn còn rất nhiều hạn chế như cách xử lý các từ hiểm quá thô sơ hay hiện tượng thiên vị độ dài.\n",
        "\n",
        "Ta có thể hạn chế được điểm yếu trên bằng cách sử dụng chuẩn hóa xác suất của một chuỗi quan sát bằng cách chia cho độ dài câu. Hay cải tiến cách xử lý từ hiếm bằng phương pháp Subword Tokenization. Hoặc đơn giản hơn, ta sử dụng các mô hình hiện đại hơn và thông minh hơn trong việc xử lý chuỗi chẳng hạn như mạng Neuron."
      ],
      "metadata": {
        "id": "B1kD0n5jQ302"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Giải thuật Viterbi\n",
        "## Giới thiệu các nhãn POS (Penn Treebank)\n",
        "\n",
        "Trong bài này, em dataset nhóm sử dụng bộ nhãn POS theo chuẩn **Penn Treebank**. Dưới đây là một số nhãn thường gặp:\n",
        "\n",
        "### 1. Danh từ (Nouns)\n",
        "\n",
        "| Tag   | Ý nghĩa                               | Ví dụ                        |\n",
        "|-------|---------------------------------------|------------------------------|\n",
        "| **NN**   | Danh từ thường, số ít                  | dog, house, book             |\n",
        "| **NNS**  | Danh từ thường, số nhiều               | dogs, houses, books          |\n",
        "| **NNP**  | Danh từ riêng, số ít                   | John, London, Tuesday        |\n",
        "| **NNPS** | Danh từ riêng, số nhiều                | Americans, Europeans         |\n",
        "\n",
        "### 2. Động từ (Verbs)\n",
        "\n",
        "| Tag   | Ý nghĩa                                             | Ví dụ                              |\n",
        "|-------|-----------------------------------------------------|------------------------------------|\n",
        "| **VB**   | Động từ nguyên mẫu                                | eat, go, run                       |\n",
        "| **VBD**  | Động từ quá khứ                                  | ate, went, ran                     |\n",
        "| **VBG**  | Hiện tại phân từ / V-ing                         | eating, going, running            |\n",
        "| **VBN**  | Quá khứ phân từ                                  | eaten, gone, broken               |\n",
        "| **VBP**  | Hiện tại, không ngôi thứ 3 số ít                 | I eat, you go                      |\n",
        "| **VBZ**  | Hiện tại, ngôi thứ 3 số ít                       | he eats, she goes                 |\n",
        "\n",
        "### 3. Tính từ & Trạng từ\n",
        "\n",
        "| Tag   | Ý nghĩa                         | Ví dụ                         |\n",
        "|-------|---------------------------------|-------------------------------|\n",
        "| **JJ**   | Tính từ                         | big, small, happy             |\n",
        "| **JJR**  | Tính từ so sánh hơn             | bigger, smaller, happier      |\n",
        "| **JJS**  | Tính từ so sánh nhất            | biggest, smallest, happiest   |\n",
        "| **RB**   | Trạng từ                        | quickly, very, well           |\n",
        "| **RBR**  | Trạng từ so sánh hơn            | faster, better                |\n",
        "| **RBS**  | Trạng từ so sánh nhất           | fastest, best                 |\n",
        "\n",
        "### 4. Đại từ, mạo từ, giới từ, liên từ\n",
        "\n",
        "| Tag    | Ý nghĩa                           | Ví dụ                         |\n",
        "|--------|-----------------------------------|--------------------------------|\n",
        "| **PRP**   | Đại từ nhân xưng                  | I, you, he, she, they          |\n",
        "| **PRP$**  | Đại từ sở hữu                     | my, your, his, her             |\n",
        "| **DT**    | Mạo từ / từ hạn định              | a, an, the, this, those        |\n",
        "| **IN**    | Giới từ / liên từ phụ thuộc       | in, on, at, of, because, if    |\n",
        "| **CC**    | Liên từ đẳng lập                  | and, or, but                   |\n",
        "| **TO**    | Từ *to* (trước động từ nguyên mẫu) | to go, to eat                  |\n",
        "\n",
        "### 5. Một số nhãn khác\n",
        "\n",
        "| Tag   | Ý nghĩa                     | Ví dụ                       |\n",
        "|-------|-----------------------------|-----------------------------|\n",
        "| **MD**   | Trợ động từ khuyết thiếu    | can, will, must, should     |\n",
        "| **CD**   | Số từ                      |  10, 20       |\n",
        "| **UH**   | Thán từ                    | oh,              |\n",
        "| **. , : ; ? !** | Dấu câu            | . , : ; ? !                 |\n",
        "\n",
        "Trong mô hình HMM, các nhãn POS ở trên chính là **trạng thái ẩn**, còn các từ trong câu là **chuỗi quan sát**. Nhiệm vụ của mô hình là, với mỗi câu đầu vào, tìm ra chuỗi nhãn POS phù hợp nhất cho từng từ.\n"
      ],
      "metadata": {
        "id": "k2IDLzZRzNFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = tag_set\n",
        "\n",
        "# Chuyển pi, A, B từ array sang dict mà hàm viterbi cần\n",
        "start_p = {\n",
        "    tag: float(pi[i])\n",
        "    for i, tag in enumerate(tag_set)\n",
        "}\n",
        "\n",
        "trans_p = {\n",
        "    tag_i: {\n",
        "        tag_j: float(A[i, j])\n",
        "        for j, tag_j in enumerate(tag_set)\n",
        "    }\n",
        "    for i, tag_i in enumerate(tag_set)\n",
        "}\n",
        "\n",
        "emit_p = {\n",
        "    tag_i: {\n",
        "        word: float(B[i, w])\n",
        "        for w, word in enumerate(vocab)\n",
        "    }\n",
        "    for i, tag_i in enumerate(tag_set)\n",
        "}"
      ],
      "metadata": {
        "id": "4q30LI_Zf6UI"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.viterbi_algorithm import *\n",
        "test_words = X_dev[1]\n",
        "gold_tags  = Y_dev[1]\n",
        "\n",
        "pred_tags, prob = viterbi_algorithm(test_words, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu test:\")\n",
        "print(test_words)\n",
        "print(\"\\nNhãn dự đoán:\")\n",
        "print(pred_tags)\n",
        "print(\"\\nNhãn gold:\")\n",
        "print(gold_tags)\n",
        "print(\"\\nXác suất:\", prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO1pyqOTgFhb",
        "outputId": "35cde313-0b66-4f54-c028-46300b1e9a1f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu test:\n",
            "['The', 'ruling', 'follows', 'a', 'host', 'of', 'problems', 'at', 'Tucson', 'Electric', ',', 'including', 'major', 'write-downs', ',', 'a', '60', '%', 'slash', 'in', 'the', 'common', 'stock', 'dividend', 'and', 'the', 'departure', 'of', 'former', 'Chairman', '<UNK>', '<UNK>', 'during', 'a', 'company', 'investigation', 'of', 'his', 'stock', 'sales', '.']\n",
            "\n",
            "Nhãn dự đoán:\n",
            "['DT', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'NNS', 'IN', 'NNP', 'NNP', ',', 'VBG', 'JJ', 'NNS', ',', 'DT', 'CD', 'NN', 'VB', 'IN', 'DT', 'JJ', 'NN', 'NN', 'CC', 'DT', 'NN', 'IN', 'JJ', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'NN', 'IN', 'PRP$', 'NN', 'NNS', '.']\n",
            "\n",
            "Nhãn gold:\n",
            "['DT', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'NNS', 'IN', 'NNP', 'NNP', ',', 'VBG', 'JJ', 'NNS', ',', 'DT', 'CD', 'NN', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NN', 'CC', 'DT', 'NN', 'IN', 'JJ', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'NN', 'IN', 'PRP$', 'NN', 'NNS', '.']\n",
            "\n",
            "Xác suất: 1.2834557554191526e-108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ed9WSxpaZpW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_sent1 = [\"he\", \"loves\" \"this\", \"subject\", \"the\", \"most\"]\n",
        "test_words1 = map_unk(raw_sent1)\n",
        "\n",
        "pred_tags1, prob1 = viterbi_algorithm(test_words1, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu gốc:\", raw_sent1)\n",
        "print(\"Câu sau khi map UNK:\", test_words1)\n",
        "print(\"Nhãn dự đoán:\", pred_tags1)\n",
        "print(\"Xác suất:\", prob1)\n",
        "\n",
        "raw_sent2 = [\"he\", \"is\", \"doing\", \"machine\", \"learning\", \"assignment\"]\n",
        "test_words2 = map_unk(raw_sent2)\n",
        "\n",
        "pred_tags2, prob2 = viterbi_algorithm(test_words2, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu gốc:\", raw_sent2)\n",
        "print(\"Câu sau khi map UNK:\", test_words2)\n",
        "print(\"Nhãn dự đoán:\", pred_tags2)\n",
        "print(\"Xác suất:\", prob2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0YpqlQngRJi",
        "outputId": "2983f7f0-025f-4a0e-9f5e-2aafed180a11"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu gốc: ['he', 'lovesthis', 'subject', 'the', 'most']\n",
            "Câu sau khi map UNK: ['he', '<UNK>', 'subject', 'the', 'most']\n",
            "Nhãn dự đoán: ['PRP', 'VBZ', 'JJ', 'DT', 'RBS']\n",
            "Xác suất: 1.367787998995333e-14\n",
            "Câu gốc: ['he', 'is', 'doing', 'machine', 'learning', 'assignment']\n",
            "Câu sau khi map UNK: ['he', 'is', 'doing', 'machine', 'learning', 'assignment']\n",
            "Nhãn dự đoán: ['PRP', 'VBZ', 'VBG', 'NN', 'VBG', 'NN']\n",
            "Xác suất: 9.515088851763234e-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khi thử một số câu tự tạo như:\n",
        "\n",
        "- \"he love this subject the most\"\n",
        "- \"he is doing machine learning assignment\"\n",
        "\n",
        "mô hình gán nhãn khá hợp lý: phân biệt đúng các đại từ (PRP), động từ chia theo chủ ngữ (VBZ), dạng V-ing (VBG), mạo từ (DT), trạng từ so sánh nhất (RBS).\n",
        "\n",
        "Các lỗi chủ yếu xuất hiện ở những cụm mơ hồ như \"machine learning\", nơi từ *learning* vừa có thể được gán là danh từ (NN) vừa có thể là động từ dạng V-ing (VBG). Đây là kiểu mơ hồ thường gặp của mô hình HMM sử dụng ngữ cảnh ngắn.\n"
      ],
      "metadata": {
        "id": "AQagqFH-_vko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "total_tokens  = 0\n",
        "\n",
        "for words, gold in zip(X_dev, Y_dev):\n",
        "    pred, _ = viterbi_algorithm(words, states, start_p, trans_p, emit_p)\n",
        "    # đếm đúng / sai cho câu này\n",
        "    for p, g in zip(pred, gold):\n",
        "        if p == g:\n",
        "            total_correct += 1\n",
        "        total_tokens += 1\n",
        "\n",
        "overall_acc = total_correct / total_tokens\n",
        "print(\"Accuracy toàn dev set:\", overall_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgPV2QGa0joI",
        "outputId": "e7b941d0-6f3b-4cb4-f2e1-7fdc645ea480"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy toàn dev set: 0.9482120089854896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nhận xét kết quả**\n",
        "\n",
        "Đoạn code trên tính **độ chính xác (accuracy)** trên tập dev theo công thức:\n",
        "\n",
        "$$\n",
        "\\text{accuracy} = \\frac{\\text{số token gán đúng nhãn}}{\\text{tổng số token}}\n",
        "$$\n",
        "\n",
        "Kết quả thu được:\n",
        "\n",
        "- **Accuracy trên dev ≈ 0.9482 (≈ 94.8%)**\n",
        "\n",
        "Như vậy, với một mô hình HMM rất cơ bản (ước lượng tham số bằng đếm tần suất có smoothing, dùng token `<UNK>` cho từ hiếm) và thuật toán Viterbi, hệ thống đã gán đúng POS cho gần **95% số từ** trong tập kiểm tra. Đây là một kết quả khá tốt đối với HMM thuần túy, cho thấy mô hình đã học được phân bố:\n",
        "\n",
        "- xác suất bắt đầu câu với từng nhãn,\n",
        "- xác suất chuyển tiếp giữa các nhãn (A),\n",
        "- xác suất phát xạ từ ứng với từng nhãn (B).\n",
        "\n",
        "Phần **~5% còn lại** chủ yếu rơi vào các trường hợp mơ hồ về từ loại, ví dụ những từ vừa có thể là danh từ vừa có thể là động từ/tính từ, hoặc các từ ít xuất hiện trong tập huấn luyện. Đây là giới hạn tự nhiên của HMM bậc 1 chỉ dùng thông tin ngữ cảnh rất ngắn (tag ngay trước), chưa tận dụng được ngữ cảnh xa hay thông tin hình thái (suffix, viết hoa, v.v.).\n",
        "\n",
        "Trong các hướng phát triển tiếp theo, có thể cải thiện bằng cách:\n",
        "- thêm đặc trưng cho từ mới (đuôi `-ing`, `-ed`, số nhiều `-s`, chữ hoa…),\n",
        "- dùng mô hình mạnh hơn như BiLSTM-CRF hoặc Transformer-based tagger,"
      ],
      "metadata": {
        "id": "98bDPNqJ-SRo"
      }
    }
  ]
}