{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangHungLN/MachineLearning_Assigment/blob/main/Assignment2/notebooks/Assignment2_CEML2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uf4-WtSBqDKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5110430e-f74c-435c-aeeb-5bee51591e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 16:58:24--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/modules/features_extractor.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4814 (4.7K) [text/plain]\n",
            "Saving to: ‘modules/features_extractor.py’\n",
            "\n",
            "\r          modules/f   0%[                    ]       0  --.-KB/s               \rmodules/features_ex 100%[===================>]   4.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 16:58:24 (39.4 MB/s) - ‘modules/features_extractor.py’ saved [4814/4814]\n",
            "\n",
            "--2025-10-09 16:58:24--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/modules/tfidf_glove.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2467 (2.4K) [text/plain]\n",
            "Saving to: ‘modules/tfidf_glove.py’\n",
            "\n",
            "modules/tfidf_glove 100%[===================>]   2.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 16:58:24 (35.8 MB/s) - ‘modules/tfidf_glove.py’ saved [2467/2467]\n",
            "\n",
            "--2025-10-09 16:58:24--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/modules/models.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2875 (2.8K) [text/plain]\n",
            "Saving to: ‘modules/models.py’\n",
            "\n",
            "modules/models.py   100%[===================>]   2.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 16:58:24 (36.0 MB/s) - ‘modules/models.py’ saved [2875/2875]\n",
            "\n",
            "--2025-10-09 16:58:24--  https://github.com/HoangHungLN/MachineLearning_Assigment/raw/refs/heads/main/Assignment2/features/tfidf_glove/Xte_w2v.npy\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/features/tfidf_glove/Xte_w2v.npy [following]\n",
            "--2025-10-09 16:58:25--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/features/tfidf_glove/Xte_w2v.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5740928 (5.5M) [application/octet-stream]\n",
            "Saving to: ‘features/tfidf_glove/Xte_w2v.npy’\n",
            "\n",
            "features/tfidf_glov 100%[===================>]   5.47M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-10-09 16:58:25 (66.0 MB/s) - ‘features/tfidf_glove/Xte_w2v.npy’ saved [5740928/5740928]\n",
            "\n",
            "--2025-10-09 16:58:25--  https://github.com/HoangHungLN/MachineLearning_Assigment/raw/refs/heads/main/Assignment2/features/tfidf_glove/Xtr_w2v.npy\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/features/tfidf_glove/Xtr_w2v.npy [following]\n",
            "--2025-10-09 16:58:25--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/features/tfidf_glove/Xtr_w2v.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46496528 (44M) [application/octet-stream]\n",
            "Saving to: ‘features/tfidf_glove/Xtr_w2v.npy’\n",
            "\n",
            "features/tfidf_glov 100%[===================>]  44.34M   191MB/s    in 0.2s    \n",
            "\n",
            "2025-10-09 16:58:26 (191 MB/s) - ‘features/tfidf_glove/Xtr_w2v.npy’ saved [46496528/46496528]\n",
            "\n",
            "--2025-10-09 16:58:26--  https://github.com/HoangHungLN/MachineLearning_Assigment/raw/refs/heads/main/Assignment2/features/tfidf_glove/Xva_w2v.npy\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/features/tfidf_glove/Xva_w2v.npy [following]\n",
            "--2025-10-09 16:58:26--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/features/tfidf_glove/Xva_w2v.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5167328 (4.9M) [application/octet-stream]\n",
            "Saving to: ‘features/tfidf_glove/Xva_w2v.npy’\n",
            "\n",
            "features/tfidf_glov 100%[===================>]   4.93M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-10-09 16:58:27 (57.8 MB/s) - ‘features/tfidf_glove/Xva_w2v.npy’ saved [5167328/5167328]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Document    Topic_group\n",
              "0  connection with icon icon dear please setup ic...       Hardware\n",
              "1  work experience user work experience user hi w...         Access\n",
              "2  requesting for meeting requesting meeting hi p...       Hardware\n",
              "3  reset passwords for external accounts re expir...         Access\n",
              "4  mail verification warning hi has got attached ...  Miscellaneous"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e27d4b88-4a2c-4064-b2c2-feb272761e59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Topic_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>connection with icon icon dear please setup ic...</td>\n",
              "      <td>Hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>work experience user work experience user hi w...</td>\n",
              "      <td>Access</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>requesting for meeting requesting meeting hi p...</td>\n",
              "      <td>Hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>reset passwords for external accounts re expir...</td>\n",
              "      <td>Access</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mail verification warning hi has got attached ...</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e27d4b88-4a2c-4064-b2c2-feb272761e59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e27d4b88-4a2c-4064-b2c2-feb272761e59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e27d4b88-4a2c-4064-b2c2-feb272761e59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eea61b09-67b5-4e28-bb41-c0c1949fa713\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eea61b09-67b5-4e28-bb41-c0c1949fa713')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eea61b09-67b5-4e28-bb41-c0c1949fa713 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "raw_data",
              "summary": "{\n  \"name\": \"raw_data\",\n  \"rows\": 47837,\n  \"fields\": [\n    {\n      \"column\": \"Document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47837,\n        \"samples\": [\n          \"issue with server process sent tuesday issue with server process hi could you please help with following issue getting once few minutes discipline lead\",\n          \"new purchase po wednesday february purchase po dear purchased please log installation please take consideration mandatory receipts section order receive item ordered kind regards administrator information\",\n          \"oracle pas urgent re we updated rights query hi can get some assistance here looks like have full control for codes only one working for cannot forecast need done by friday thanks programme portfolio officer mobile phone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Access\",\n          \"Administrative rights\",\n          \"Hardware\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "##Xử lý dữ liệu\n",
        "\n",
        "#Import thư viện\n",
        "import re, regex as re2, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "import os\n",
        "from scipy import sparse\n",
        "from IPython.display import display\n",
        "plt.style.use(\"seaborn-v0_8\"); sns.set_palette(\"Set2\")  #Định dạng bảng\n",
        "\n",
        "os.makedirs(\"modules\", exist_ok= True)\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/modules/features_extractor.py -O modules/features_extractor.py\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/modules/tfidf_glove.py -O modules/tfidf_glove.py\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/modules/models.py -O modules/models.py\n",
        "\n",
        "os.makedirs(\"features/tfidf_glove\", exist_ok= True)\n",
        "!wget https://github.com/HoangHungLN/MachineLearning_Assigment/raw/refs/heads/main/Assignment2/features/tfidf_glove/Xte_w2v.npy -O features/tfidf_glove/Xte_w2v.npy\n",
        "!wget https://github.com/HoangHungLN/MachineLearning_Assigment/raw/refs/heads/main/Assignment2/features/tfidf_glove/Xtr_w2v.npy -O features/tfidf_glove/Xtr_w2v.npy\n",
        "!wget https://github.com/HoangHungLN/MachineLearning_Assigment/raw/refs/heads/main/Assignment2/features/tfidf_glove/Xva_w2v.npy -O features/tfidf_glove/Xva_w2v.npy\n",
        "#Tải dữ liệu bảng CSV từ github\n",
        "dataset_url = \"https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment2/data/all_tickets_processed_improved_v3.csv\"\n",
        "raw_data = pd.read_csv(dataset_url)\n",
        "raw_data = raw_data.replace({r'â€‰':'', r'\\u2009':''}, regex=True)  #Làm sạch dữ liệu\n",
        "\n",
        "#In thử 5 dòng đầu\n",
        "raw_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kiểm tra số lượng mẫu và thuộc tính gốc của dữ liệu\n",
        "print (\"Số lượng mẫu có trong dataset là:\", raw_data.shape[0])\n",
        "print (\"Số lượng thuộc tính có trong dataset là:\", raw_data.shape[1])"
      ],
      "metadata": {
        "id": "pUhrlkHmrXxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8174e9d-0fa0-49d7-9713-11ad80f04839"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng mẫu có trong dataset là: 47837\n",
            "Số lượng thuộc tính có trong dataset là: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra dữ liệu null và trùng lặp\n",
        "print(raw_data.isna().sum().sort_values(ascending=False).head())\n",
        "print(\"Duplicates:\", raw_data.duplicated().sum())\n",
        "\n",
        "# Xác định cột văn bản và cột nhãn\n",
        "obj_cols = [c for c in raw_data.columns if raw_data[c].dtype=='object']\n",
        "text_col = max(obj_cols, key=lambda c: raw_data[c].astype(str).str.len().mean())\n",
        "label_col = [c for c in raw_data.columns if c != text_col][0]  # dataset có 2 cột\n",
        "\n",
        "print(\"text_col:\", text_col, \"label_col:\", label_col)\n",
        "\n",
        "# Thống kê phân phối nhãn\n",
        "vc = raw_data[label_col].value_counts()\n",
        "display(vc.head()); (vc/vc.sum()).head()\n",
        "\n",
        "# Thống kê độ dài văn bản\n",
        "lens = raw_data[text_col].astype(str).str.split().map(len)\n",
        "print(lens.describe())\n",
        "plt.figure(); lens.hist(bins=50); plt.title('Token count'); plt.xlabel('tokens'); plt.ylabel('freq'); plt.show()\n",
        "\n",
        "# Đề xuất max_len và vocab_limit\n",
        "max_len = int(np.percentile(lens, 95))  # gợi ý\n",
        "vocab_limit = 30000"
      ],
      "metadata": {
        "id": "TSigZv2jtQuS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "outputId": "e7c96020-ee31-432c-af66-6b454e510623"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document       0\n",
            "Topic_group    0\n",
            "dtype: int64\n",
            "Duplicates: 0\n",
            "text_col: Document label_col: Topic_group\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Topic_group\n",
              "Hardware         13617\n",
              "HR Support       10915\n",
              "Access            7125\n",
              "Miscellaneous     7060\n",
              "Storage           2777\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic_group</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Hardware</th>\n",
              "      <td>13617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR Support</th>\n",
              "      <td>10915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Access</th>\n",
              "      <td>7125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Miscellaneous</th>\n",
              "      <td>7060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Storage</th>\n",
              "      <td>2777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    47837.000000\n",
            "mean        43.597341\n",
            "std         56.736800\n",
            "min          2.000000\n",
            "25%         17.000000\n",
            "50%         26.000000\n",
            "75%         46.000000\n",
            "max        981.000000\n",
            "Name: Document, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nhận xét về dữ liệu**\n",
        "\n",
        "*Tính sạch của dữ liệu*\n",
        "\n",
        "- Không có giá trị bị thiếu (NaN).\n",
        "\n",
        "- Không có dòng trùng lặp.\n",
        "\n",
        "-> Dữ liệu gốc rất sạch, không cần xử lý thiếu/trùng.\n",
        "\n",
        "*Cột dữ liệu*\n",
        "\n",
        "- Document: cột chứa văn bản (mô tả sự cố IT).\n",
        "\n",
        "- Topic_group: cột nhãn phân loại (loại sự cố).\n",
        "\n",
        "*Phân phối nhãn*\n",
        "\n",
        "- 5 nhóm chính:\n",
        "\n",
        "- Hardware: 13,617 mẫu\n",
        "\n",
        "- HR Support: 10,915 mẫu\n",
        "\n",
        "- Access: 7,125 mẫu\n",
        "\n",
        "- Miscellaneous: 7,060 mẫu\n",
        "\n",
        "- Storage: 2,777 mẫu\n",
        "\n",
        "-> Các nhãn hơi mất cân bằng: Hardware nhiều gấp gần 5 lần Storage.\n",
        "Cần lưu ý khi huấn luyện mô hình (có thể dùng class weights).\n",
        "\n",
        "*Độ dài văn bản*\n",
        "\n",
        "- Trung bình: ~44 từ.\n",
        "\n",
        "- Median (50% dữ liệu): 26 từ.\n",
        "\n",
        "- 75% dữ liệu: ≤ 46 từ.\n",
        "\n",
        "- Văn bản dài nhất: 981 từ.\n",
        "\n",
        "-> Biểu đồ histogram cho thấy đa số văn bản rất ngắn (<50 từ), chỉ một số ít cực dài → phân phối lệch phải (skewed).\n",
        "\n",
        "*Tham số tiền xử lý đề xuất*\n",
        "\n",
        "- max_len = ~120 (percentile 95) -> đủ bao phủ 95% dữ liệu, tránh bị outlier kéo dài.\n",
        "\n",
        "- vocab_limit = 30,000 -> giới hạn từ vựng cho tokenizer, cân bằng giữa hiệu quả và tài nguyên."
      ],
      "metadata": {
        "id": "cPqzf5P-suwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chia train 80%, test 10%, validation 10%\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(raw_data, test_size=0.1, stratify=raw_data[label_col], random_state=42)\n",
        "train, val  = train_test_split(train,    test_size=0.1, stratify=train[label_col],    random_state=42)"
      ],
      "metadata": {
        "id": "IGXxks9Pug38"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Gộp toàn bộ dữ liệu (nếu bạn có train / val / test)\n",
        "all_text = pd.concat([train[text_col], val[text_col], test[text_col]], ignore_index=True)\n",
        "\n",
        "# Regex: tìm ký tự KHÔNG phải chữ (A-Z a-z) và KHÔNG phải số (0-9)\n",
        "pattern = re.compile(r\"[^A-Za-z0-9]\")\n",
        "\n",
        "# Dòng nào chứa ký tự không phải chữ/số\n",
        "mask = all_text.str.contains(pattern)\n",
        "\n",
        "# Thống kê\n",
        "count_special = mask.sum()\n",
        "total = len(all_text)\n",
        "\n",
        "print(f\"Số dòng chứa ký tự không phải chữ/số: {count_special}/{total} ({count_special/total:.2%})\")\n",
        "\n",
        "# In vài ví dụ\n",
        "print(\"\\nVí dụ các dòng có ký tự không phải chữ/số:\")\n",
        "print(all_text[mask].sample(min(10, count_special), random_state=42).tolist())"
      ],
      "metadata": {
        "id": "BmNB6U9p0UaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4840e73c-3b53-4dbb-c41b-26b55e772035"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số dòng chứa ký tự không phải chữ/số: 47837/47837 (100.00%)\n",
            "\n",
            "Ví dụ các dòng có ký tự không phải chữ/số:\n",
            "['oracle task list malfunction task list malfunction hello task list does remove task when complete still appears have items review action upon same upper right hand corner thank you unit manager', 'outlook calendar issue calendar hi when click scheduling tab within meeting invite able anyone calendars know if available attend meetings can you please fix for going for over week please attached thank you advertising', 'please remove access for from please hi please best regards design lead', 'new project code request thursday november pm re code please thursday november pm code hi raised requested please let needs created well thank kind regards analyst ext hub thursday november pm code good morning please attached thanks officer', 'check if access to is still needed tuesday pm re devices hi apologies thought had replied remember looking approved requester how required duration disabled removing user once devices required once requester has confirmed duration trigger action period also expected duration more than months requirement re validated months trigger action months maximum thanks', 'please as prospect friday pm please prospect hi since contract signed please prospect instead active client thanks', 'staff membership friday membership dear colleagues excluded groups please include tower groups please also provide details about reason removed weird things ad frustrating thank senior engineer information confidential legally privileged intended solely addressee opinions expressed mine', 'license wednesday november license hello license order work assigned help key possible thanks best regards software developer', 'new list friday july hi please create code contents also please add thank officer floor blvd district', 'contractor update contractor update dear please note entity previously thank october pm contractor complete hi please find attached completed starter form kind regards october pm re contractor complete hi sorry delay getting back let further thanks october contractor complete dear please help completed form join thank lead']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import thư viện\n",
        "!pip -q install emoji unidecode\n",
        "import nltk; nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sk_sw\n",
        "from nltk.corpus import stopwords\n",
        "from emoji import replace_emoji\n",
        "from unidecode import unidecode\n",
        "import unicodedata\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "std_english_stop = set(stopwords.words('english')) | set(sk_sw)"
      ],
      "metadata": {
        "id": "ZrjkUb0-uqlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad7d5be-7be1-4374-84a0-0a0de54a6dc8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict, Any, Set\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def mine_stopwords_topPct_coef(\n",
        "    corpus: List[str],           # TRAIN texts (đã clean sơ bộ, CHƯA remove stopwords)\n",
        "    y: np.ndarray,               # TRAIN labels\n",
        "    *,\n",
        "    ngram_range: Tuple[int,int]=(1,2),\n",
        "    min_df: int|float=2,         # bỏ token quá hiếm khi vectorize\n",
        "    top_pct: float=0.10,         # lấy Top-X% DF làm candidate (vd 0.10 = 10%)\n",
        "    lowercase: bool=False,\n",
        "    use_binary: bool=True,       # dùng X>0 cho LR để tránh thiên lệch do lặp\n",
        "    class_weight: str|dict=\"balanced\",\n",
        "    max_iter: int=300,\n",
        "    # chọn “gần 0” theo 1 trong 2 cách:\n",
        "    mode: str=\"frac\",            # 'frac' | 'eps'\n",
        "    bottom_frac: float=0.05,     # nếu mode='frac': lấy bottom 5% theo |coef|\n",
        "    eps: float=1e-2,             # nếu mode='eps' : chọn |coef| <= eps\n",
        "    verbose: bool=True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    1) Chọn Top-X% token theo DF làm candidate.\n",
        "    2) Train LogisticRegression(class_weight='balanced') trên tập candidate.\n",
        "    3) Lọc các token có |coef| ≈ 0 => stopwords domain.\n",
        "\n",
        "    Trả về: {'stopwords', 'vocab', 'candidates', 'coef_abs', 'top_idx', 'df'}\n",
        "    \"\"\"\n",
        "    # ----- Vectorize toàn bộ (để tính DF) -----\n",
        "    vec = CountVectorizer(ngram_range=ngram_range, min_df=min_df,\n",
        "                          lowercase=lowercase, stop_words=None)\n",
        "    X = vec.fit_transform(corpus)                      # sparse [n_samples, n_features]\n",
        "    vocab = vec.get_feature_names_out()\n",
        "    n_docs = X.shape[0]\n",
        "    df = (X > 0).sum(axis=0).A1\n",
        "\n",
        "    # ----- Top-X% theo DF làm candidates -----\n",
        "    m = len(vocab)\n",
        "    k = max(1, int(top_pct * m))\n",
        "    order = df.argsort()[::-1]                        # desc DF\n",
        "    top_idx = order[:k]\n",
        "    cand_vocab = vocab[top_idx]\n",
        "\n",
        "    # ----- Ma trận cho LR -----\n",
        "    Xc = X[:, top_idx]\n",
        "    if use_binary:\n",
        "        Xc = (Xc > 0).astype(int)                     # binary presence\n",
        "\n",
        "    # ----- Train LR (balanced) -----\n",
        "    clf = LogisticRegression(\n",
        "        class_weight=class_weight,\n",
        "        max_iter=max_iter,\n",
        "        n_jobs=None if hasattr(LogisticRegression(), \"n_jobs\") else None\n",
        "    )\n",
        "    clf.fit(Xc, y)\n",
        "\n",
        "    # Lấy |coef| (n_classes x k) -> trung bình theo lớp\n",
        "    coef_abs = np.abs(clf.coef_).mean(axis=0)         # shape (k,)\n",
        "\n",
        "    # ----- Chọn “gần 0” -----\n",
        "    if mode == \"frac\":\n",
        "        bw = max(1, int(bottom_frac * len(coef_abs))) # bottom k%\n",
        "        weak_local_idx = np.argsort(coef_abs)[:bw]\n",
        "        stopwords_auto = set(cand_vocab[weak_local_idx])\n",
        "    elif mode == \"eps\":\n",
        "        weak_local_idx = np.where(coef_abs <= eps)[0]\n",
        "        stopwords_auto = set(cand_vocab[weak_local_idx])\n",
        "    else:\n",
        "        raise ValueError(\"mode phải là 'frac' hoặc 'eps'.\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[INFO] vocab={m:,}, X={X.shape}, nnz={X.nnz:,}\")\n",
        "        print(f\"[INFO] candidates (Top {int(top_pct*100)}% DF) = {len(cand_vocab):,}\")\n",
        "        if mode == \"frac\":\n",
        "            print(f\"[INFO] stopwords (|coef| bottom {int(bottom_frac*100)}%) = {len(stopwords_auto):,}\")\n",
        "        else:\n",
        "            print(f\"[INFO] stopwords (|coef| <= {eps}) = {len(stopwords_auto):,}\")\n",
        "        # Ví dụ vài từ “gần 0”\n",
        "        ex = sorted(list(stopwords_auto))[:30]\n",
        "        print(\"[SAMPLE]\", ex)\n",
        "\n",
        "    return {\n",
        "        \"stopwords\": stopwords_auto,\n",
        "        \"vocab\": vocab,\n",
        "        \"candidates\": cand_vocab,\n",
        "        \"coef_abs\": coef_abs,     # |coef| tương ứng với cand_vocab\n",
        "        \"top_idx\": top_idx,\n",
        "        \"df\": df\n",
        "    }"
      ],
      "metadata": {
        "id": "BwvB0uIwUg8j"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_stopset(stopset):\n",
        "    out = set()\n",
        "    for t in stopset:\n",
        "        if not isinstance(t, str):\n",
        "            continue\n",
        "        t = t.strip().lower()\n",
        "        if not t:\n",
        "            continue\n",
        "        # tách theo khoảng trắng, chỉ giữ token chữ/số (đã clean lowercase từ trước)\n",
        "        parts = re.findall(r\"\\w+\", t)\n",
        "        out.update(parts)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oBmJ_DqAVH4Y"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self, lower=True, strip_accents=False,\n",
        "                 remove_urls=True, remove_emojis=True,\n",
        "                 remove_special=True, remove_numbers=False,\n",
        "                 remove_stopwords=True, stopwords=None,\n",
        "                 max_words=30000, max_len=128, oov_token='<OOV>'):\n",
        "        # Thiết lập tham số tiền xử lý\n",
        "        self.lower = lower\n",
        "        self.strip_accents = strip_accents\n",
        "        self.remove_urls = remove_urls\n",
        "        self.remove_emojis = remove_emojis\n",
        "        self.remove_special = remove_special\n",
        "        self.remove_numbers = remove_numbers\n",
        "        self.remove_stopwords = remove_stopwords\n",
        "        # stopwords: set các token đã chuẩn hóa lowercase\n",
        "        self.stop = set(stopwords) if stopwords else set()\n",
        "\n",
        "        # Tokenizer để biến từ thành số\n",
        "        self.tok = Tokenizer(num_words=max_words, oov_token=oov_token)\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def _clean(self, s):\n",
        "        # Làm sạch 1 câu văn bản\n",
        "        if not isinstance(s, str):\n",
        "            # ép kiểu an toàn nếu lỡ là bytes/number\n",
        "            try:\n",
        "                s = s.decode('utf-8', errors='ignore')\n",
        "            except Exception:\n",
        "                s = str(s)\n",
        "\n",
        "        # Chuẩn hóa Unicode + loại một số zero-width phổ biến\n",
        "        s = unicodedata.normalize('NFKC', s)\n",
        "        s = s.replace('\\u2009', '').replace('\\u200b', '')\n",
        "\n",
        "        if self.lower:\n",
        "            s = s.lower()\n",
        "        if self.strip_accents:\n",
        "            s = unidecode(s)\n",
        "\n",
        "        # URL / email / mention / hashtag (thay bằng khoảng trắng để tránh dính chữ)\n",
        "        if self.remove_urls:\n",
        "            s = re.sub(r'(https?://\\S+|www\\.\\S+|[\\w\\.-]+@[\\w\\.-]+\\.\\w+|@\\w+|#\\w+)', ' ', s)\n",
        "\n",
        "        # Emoji → xóa (hoặc thay bằng khoảng trắng)\n",
        "        if self.remove_emojis:\n",
        "            s = replace_emoji(s, replace=' ')\n",
        "\n",
        "        # Loại ký tự đặc biệt, giữ chữ cái (cả tiếng Việt), số và khoảng trắng\n",
        "        if self.remove_special:\n",
        "            s = re2.sub(r\"[^\\p{L}\\p{N}\\s]\", \" \", s)\n",
        "\n",
        "        # Loại số nếu cần\n",
        "        if self.remove_numbers:\n",
        "            s = re.sub(r\"\\d+(\\.\\d+)?\", \" \", s)\n",
        "\n",
        "        # Tokenize đơn giản theo \\w+ (UNIDODE) rồi remove stopwords nếu bật\n",
        "        toks = re.findall(r\"\\w+\", s, flags=re.UNICODE)\n",
        "        if self.remove_stopwords and self.stop:\n",
        "            toks = [t for t in toks if t not in self.stop]\n",
        "\n",
        "        # Ghép lại & chuẩn hóa khoảng trắng\n",
        "        return \" \".join(toks).strip()\n",
        "\n",
        "    def fit(self, texts):\n",
        "        # Làm sạch + xây dựng từ điển từ train\n",
        "        cleaned = [self._clean(t) for t in texts]\n",
        "        self.tok.fit_on_texts(cleaned)\n",
        "        return cleaned\n",
        "\n",
        "    def transform(self, texts):\n",
        "        # Làm sạch + chuyển văn bản thành số + padding\n",
        "        cleaned = [self._clean(t) for t in texts]\n",
        "        seq = self.tok.texts_to_sequences(cleaned)\n",
        "        pad = pad_sequences(seq, maxlen=self.max_len, padding='post', truncating='post')\n",
        "        return pad, cleaned\n",
        "\n",
        "    def fit_transform(self, texts):\n",
        "        # Kết hợp fit và transform cho tập train\n",
        "        cleaned = self.fit(texts)\n",
        "        seq = self.tok.texts_to_sequences(cleaned)\n",
        "        pad = pad_sequences(seq, maxlen=self.max_len, padding='post', truncating='post')\n",
        "        return pad, cleaned"
      ],
      "metadata": {
        "id": "31Ce_hx1uyqF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo bộ tiền xử lý với tham số đã chọn\n",
        "tp_basic = TextPreprocessor(\n",
        "    lower=True,\n",
        "    strip_accents=False,\n",
        "    remove_urls=True,\n",
        "    remove_emojis=True,\n",
        "    remove_special=True,\n",
        "    remove_numbers=True,     # giữ lại số (mã lỗi, version có thể quan trọng)\n",
        "    remove_stopwords=False,\n",
        "    stopwords=None,\n",
        "    max_words=vocab_limit,    # giới hạn từ vựng\n",
        "    max_len=max_len           # chiều dài chuỗi sau padding\n",
        ")\n",
        "\n",
        "# Tiền xử lý văn bản -> chuyển thành chuỗi số đã padding\n",
        "_,tr_cleaned = tp_basic.fit_transform(train[text_col].astype(str))   # fit trên train\n",
        "_,va_cleaned = tp_basic.transform(val[text_col].astype(str))         # transform val\n",
        "_, te_cleaned = tp_basic.transform(test[text_col].astype(str))        # transform test\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "ytr = le.fit_transform(train[label_col])\n",
        "yva = le.transform(val[label_col])\n",
        "yte = le.transform(test[label_col])\n",
        "res = mine_stopwords_topPct_coef(\n",
        "    corpus=tr_cleaned, y=ytr,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    top_pct=0.005,\n",
        "    lowercase=False,\n",
        "    use_binary=True,\n",
        "    class_weight=\"balanced\",\n",
        "    max_iter=300,\n",
        "    mode=\"frac\",         # lấy bottom theo tỉ lệ\n",
        "    bottom_frac=0.02,    # bottom 5% |coef|\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "DOMAIN_STOP_AUTO = normalize_stopset(res[\"stopwords\"])\n",
        "FINAL_STOPWORDS = (DOMAIN_STOP_AUTO) | std_english_stop\n",
        "\n",
        "tp = TextPreprocessor(\n",
        "    lower=True, strip_accents=False,\n",
        "    remove_urls=True, remove_emojis=True,\n",
        "    remove_special=True, remove_numbers=True,\n",
        "    remove_stopwords=True,\n",
        "    stopwords=FINAL_STOPWORDS\n",
        ")\n",
        "_, tr_clean = tp.fit_transform(train[text_col].astype(str))\n",
        "_, va_clean = tp.transform(val[text_col].astype(str))\n",
        "_, te_clean = tp.transform(test[text_col].astype(str))\n"
      ],
      "metadata": {
        "id": "IVLYMRWyu0tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c76e01-8c35-46fe-881c-0c3e266c8c50"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] vocab=146,485, X=(38747, 146485), nnz=2,323,896\n",
            "[INFO] candidates (Top 0% DF) = 732\n",
            "[INFO] stopwords (|coef| bottom 2%) = 14\n",
            "[SAMPLE] ['about', 'ask', 'dear', 'each subsidiaries', 'for', 'friday', 'march', 'new purchase', 'number whose', 'registered old', 'same', 'street kingdom', 'the', 'whose registered']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Số lượng stopwords domain:\", len(DOMAIN_STOP_AUTO))\n",
        "print(\"Một vài stopwords domain:\", list(sorted(DOMAIN_STOP_AUTO))[:30])\n",
        "print(\"Tổng Số lượng stopwords:\", len(FINAL_STOPWORDS))\n",
        "print(\"Một vài stopwords:\", list(sorted(FINAL_STOPWORDS))[:30])"
      ],
      "metadata": {
        "id": "5fuabW4qy0yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abf6fec-9757-4abc-f389-75cfa8fbc31c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng stopwords domain: 18\n",
            "Một vài stopwords domain: ['about', 'ask', 'dear', 'each', 'for', 'friday', 'kingdom', 'march', 'new', 'number', 'old', 'purchase', 'registered', 'same', 'street', 'subsidiaries', 'the', 'whose']\n",
            "Tổng Số lượng stopwords: 409\n",
            "Một vài stopwords: ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'ain', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = train[text_col].iloc[0]         # lấy 1 văn bản gốc từ tập train\n",
        "_, c = tp.transform([s])            # tiền xử lý văn bản\n",
        "print(\"RAW:\", s)                    # in ra bản gốc\n",
        "print(\"CLEAN:\", c[0])               # in ra bản đã làm sạch"
      ],
      "metadata": {
        "id": "U9qkgH9Xu4_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173fc60d-b622-40d4-fd80-585ba598a16e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAW: stage is catalogue item removed sent friday stage catalogue item removed hello could you please have look stage set catalog item removed cannot be changed could you please amend we resolve request kind regards specialist\n",
            "CLEAN: stage catalogue item removed sent stage catalogue item removed hello look stage set catalog item removed changed amend resolve request kind regards specialist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Features extraction (Trích xuất đặc trưng dữ liệu)**\n",
        "\n",
        "Ở bước này, nhóm em lựa chọn ba phương pháp trích xuất đặc trưng chính để biểu diễn dữ liệu văn bản:  \n",
        "1. **BoW (Bag of Words)**  \n",
        "2. **TF–IDF (Term Frequency – Inverse Document Frequency)**  \n",
        "3. **TF–IDF Weighted GloVe Embedding** – kết hợp giữa mô hình GloVe và trọng số TF–IDF.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Các phương pháp trích xuất đặc trưng**\n",
        "\n",
        "### BoW (Bag of Words)\n",
        "Phương pháp BoW biểu diễn mỗi văn bản dưới dạng vector dựa trên **tần suất xuất hiện của từ** trong tập dữ liệu.  \n",
        "Các từ trong toàn bộ tập văn bản được đưa vào một “từ điển”, và mỗi câu được biến thành một vector chứa số lần xuất hiện của từng từ trong từ điển đó.  \n",
        "- **Ưu điểm:** Đơn giản, dễ triển khai.  \n",
        "- **Nhược điểm:** Không nắm bắt được ngữ nghĩa hoặc thứ tự từ.  \n",
        "\n",
        "**Cấu hình mặc định trong pipeline:**\n",
        "- `max_features = 5000`  \n",
        "- `ngram_range = (1, 2)` (sử dụng cả unigram và bigram)  \n",
        "- `min_df = 2`, `max_df = 0.9` (loại bỏ từ quá hiếm hoặc quá phổ biến)  \n",
        "- `lowercase = False` (vì dữ liệu đã được chuẩn hóa từ bước preprocessing)  \n",
        "\n",
        "---\n",
        "\n",
        "### TF–IDF (Term Frequency – Inverse Document Frequency)\n",
        "Phương pháp TF–IDF mở rộng từ BoW, gán trọng số cho mỗi từ dựa trên **tần suất xuất hiện trong một văn bản (TF)** và **độ hiếm trong toàn bộ tập dữ liệu (IDF)**.  \n",
        "Điều này giúp giảm ảnh hưởng của các từ phổ biến và làm nổi bật các từ mang thông tin đặc trưng hơn.  \n",
        "- **Ưu điểm:** Giúp mô hình chú ý đến các từ quan trọng.  \n",
        "- **Nhược điểm:** Vẫn chưa nắm bắt được ngữ nghĩa ngữ cảnh của từ.\n",
        "\n",
        "**Cấu hình trong pipeline:**\n",
        "- `max_features = 5000`  \n",
        "- `ngram_range = (1, 2)`  \n",
        "- `min_df = 2`, `max_df = 0.9`  \n",
        "- `sublinear_tf = True` (giảm ảnh hưởng từ có tần suất quá cao)  \n",
        "- `use_idf = True` (kích hoạt trọng số nghịch đảo IDF)  \n",
        "\n",
        "---\n",
        "\n",
        "### TF–IDF Weighted GloVe Embedding\n",
        "Phương pháp này kết hợp giữa **mô hình nhúng từ GloVe** (Global Vectors for Word Representation) và **trọng số TF–IDF** để tạo biểu diễn câu có ý nghĩa ngữ nghĩa hơn.  \n",
        "\n",
        "Cụ thể:\n",
        "1. Mỗi từ trong văn bản được ánh xạ sang vector GloVe (kích thước 300 chiều).  \n",
        "2. Trọng số TF–IDF được tính cho từng từ.  \n",
        "3. Vector biểu diễn của câu được tính bằng trung bình có trọng số TF–IDF của các vector từ.\n",
        "\n",
        "\n",
        "**Cấu hình trong pipeline:**\n",
        "- Mô hình tiền huấn luyện: 2024 Wikipedia + Gigaword 5 (11.9B tokens, 1.2M vocab, uncased, 300d vectors, 1.6 GB download)[Tải tại đây](https://nlp-stanford-edu.translate.goog/data/wordvecs/glove.2024.wikigiga.300d.zip?_x_tr_sl=en&_x_tr_tl=vi&_x_tr_hl=vi&_x_tr_pto=tc)\n",
        "- Kích thước vector: `300`  \n",
        "- Tokenizer: tách từ bằng regex `\\w+`  \n",
        "- Vector câu: trung bình có trọng số TF–IDF  \n",
        "\n",
        "**Ưu điểm:**  \n",
        "- Giữ được thông tin ngữ nghĩa của GloVe.  \n",
        "- Kết hợp được độ quan trọng thống kê của TF–IDF.  \n",
        "\n",
        "**Chú ý**\n",
        "- Quá trình tính TF–IDF Weighted GloVe mất nhiều thời gian (~15 phút/lần chạy), nên nhóm em tách phần xử lý này sang file `tfidf_glove.py` và chỉ sử dụng các file đặc trưng `.npy` được trích xuất sẵn từ đợt huấn luyện trong lúc làm bài và lưu trong github nhóm để huấn luyện mô hình.\n",
        "\n",
        "---\n",
        "\n",
        "## **Tổng kết**\n",
        "\n",
        "- Hai phương pháp trích xuất đặc trưng cổ điển **BoW** và **TF–IDF** được triển khai trong file `features_extractor.py`.  \n",
        "  Các ma trận đặc trưng của hai phương pháp này được lưu dưới dạng file `.npz` để phục vụ cho quá trình huấn luyện và đánh giá mô hình.  \n",
        "  Hàm `report_vectorizer()` được sử dụng để in ra các thông số cấu hình và thống kê như số chiều đặc trưng, độ thưa (density) và kích thước từ vựng của từng phương pháp.  \n",
        "\n",
        "- Phương pháp **TF–IDF Weighted GloVe Embedding** được triển khai riêng trong file `tfidf_glove.py`.  \n",
        "- Do quá trình trích xuất đặc trưng này kết hợp giữa mô hình GloVe kích thước 300 chiều và trọng số TF–IDF nên mất nhiều thời gian xử lý (khoảng 10–15 phút). Vì vậy, nhóm em chỉ thực hiện tính toán một lần duy nhất, sau đó lưu kết quả đặc trưng ra file `.npy` để sử dụng làm đầu vào cho các mô hình huấn luyện sau này.\n",
        "## **Về `tfidf_glove.py`**\n",
        "\n",
        "- **Phiên bản thư viện**\n",
        "  - `scipy == 1.12.*`\n",
        "  - `gensim == 4.3.2`\n",
        "\n",
        "- **Bộ vector từ**\n",
        "  - `glove.2024.wikigiga.300d.zip` tải từ: https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.300d.zip\n",
        "  - Sử dụng tệp 300 chiều sau khi giải nén; chuyển sang định dạng Word2Vec bằng `glove2word2vec`.\n",
        "\n",
        "- **Ghi chú triển khai**\n",
        "  - Tokenization đơn giản theo `\\w+` trên văn bản đã được làm sạch.\n",
        "  - Fit `TfidfVectorizer` trên **train** để lấy IDF; câu vector = trung bình có trọng số **TF × IDF** của các word vectors GloVe.\n",
        "  - Kết quả đặc trưng được lưu dạng `.npy` tại `features/tfidf_glove/` (train/val/test).\n",
        "\n",
        "- **Lệnh cài đặt nhanh trong Colab**\n",
        "  ```bash\n",
        "  !pip install \"scipy==1.12.*\" gensim==4.3.2\n",
        "  !wget \"https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.300d.zip\"\n",
        "  !unzip -q glove.2024.wikigiga.300d.zip -d glove.2024.300d"
      ],
      "metadata": {
        "id": "1kvmFfICqgw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.features_extractor import *\n",
        "sum_bow = features_extractor_classic(\n",
        "    tr_clean, va_clean, te_clean,\n",
        "    mode=\"BoW\",\n",
        "    max_features=20000,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.9,\n",
        ")\n",
        "\n",
        "Xtr_bow = sparse.load_npz(\"features/bow/Xtr.npz\")\n",
        "Xva_bow = sparse.load_npz(\"features/bow/Xva.npz\")\n",
        "Xte_bow = sparse.load_npz(\"features/bow/Xte.npz\")\n",
        "print(sum_bow)\n",
        "\n",
        "sum_tfidf = features_extractor_classic(\n",
        "    tr_clean, va_clean, te_clean,\n",
        "    mode=\"TFIDF\",\n",
        "    max_features=20000,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.9,\n",
        ")\n",
        "Xtr_tfidf = sparse.load_npz(\"features/tfidf/Xtr.npz\")\n",
        "Xva_tfidf = sparse.load_npz(\"features/tfidf/Xva.npz\")\n",
        "Xte_tfidf = sparse.load_npz(\"features/tfidf/Xte.npz\")\n",
        "print(sum_tfidf)"
      ],
      "metadata": {
        "id": "HcfTy4EEHpBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3bbb517-ab93-4ae7-f32e-2c6116251f45"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================\n",
            "Bag-of-Words Report\n",
            "===================\n",
            "\n",
            ">>> Vectorizer params:\n",
            "  - type: CountVectorizer\n",
            "  - ngram_range: (1, 2)\n",
            "  - min_df: 2\n",
            "  - max_df: 0.9\n",
            "  - max_features: 20000\n",
            "  - lowercase: False\n",
            "  - token_pattern: (?u)\\b\\w\\w+\\b\n",
            "  - use_idf: None\n",
            "  - sublinear_tf: None\n",
            "  - stop_words: None\n",
            "  - vocab_size: 20000\n",
            "\n",
            ">>> Matrix stats:\n",
            "  [Train] shape=(38747, 20000)  nnz=1,398,193  density=0.001804\n",
            "  [Val] shape=(4306, 20000)  nnz=154,848  density=0.001798\n",
            "  [Test] shape=(4784, 20000)  nnz=171,846  density=0.001796\n",
            "=============\n",
            "TF-IDF Report\n",
            "=============\n",
            "\n",
            ">>> Vectorizer params:\n",
            "  - type: TfidfVectorizer\n",
            "  - ngram_range: (1, 2)\n",
            "  - min_df: 2\n",
            "  - max_df: 0.9\n",
            "  - max_features: 20000\n",
            "  - lowercase: False\n",
            "  - token_pattern: (?u)\\b\\w\\w+\\b\n",
            "  - use_idf: True\n",
            "  - sublinear_tf: True\n",
            "  - stop_words: None\n",
            "  - vocab_size: 20000\n",
            "\n",
            ">>> Matrix stats:\n",
            "  [Train] shape=(38747, 20000)  nnz=1,398,193  density=0.001804\n",
            "  [Val] shape=(4306, 20000)  nnz=154,848  density=0.001798\n",
            "  [Test] shape=(4784, 20000)  nnz=171,846  density=0.001796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr_w2v = np.load(\"features/tfidf_glove/Xtr_w2v.npy\")\n",
        "Xva_w2v = np.load(\"features/tfidf_glove/Xva_w2v.npy\")\n",
        "Xte_w2v = np.load(\"features/tfidf_glove/Xte_w2v.npy\")"
      ],
      "metadata": {
        "id": "cq23QyybmJ8y"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "919d6d8e"
      },
      "source": [
        "#Tìm mô hình tối ưu\n",
        "Chạy các mô hình Naive Bayes, SVM, Logistic Regression với 3 bộ tham số khác nhau cho mỗi mô hình và với 3 loại embedding (BoW, TF-IDF, GloVe)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1e112e5"
      },
      "source": [
        "Cài đặt bộ tham số cần đánh giá cho từng mô hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5845849"
      },
      "source": [
        "model_params = {\n",
        "    'NaiveBayes': [\n",
        "        {'alpha': 0.1},\n",
        "        {'alpha': 1.0},\n",
        "        {'alpha': 0.5}\n",
        "    ],\n",
        "    'LogisticRegression': [\n",
        "        {'C': 0.1, 'max_iter': 1000},\n",
        "        {'C': 1.0, 'max_iter': 1000},\n",
        "        {'C': 10.0, 'max_iter': 1000}\n",
        "    ],\n",
        "    'SVM': [\n",
        "        {'C': 0.1},\n",
        "        {'C': 1.0}\n",
        "        #{'C': 10.0}\n",
        "        #Nhóm đã thử với C = 10.0 tuy nhiên độ chính xác của mô hình không tăng\n",
        "        #Nhận thấy SVM chạy rất tốn thời gian nên nhóm đã bỏ ra khỏi mô hình để tránh quá mất thời gian.\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KcGCcLKU75C2"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e018e97",
        "outputId": "82635a2b-4eb7-4547-92e3-41abe6b6968e"
      },
      "source": [
        "import inspect\n",
        "\n",
        "# Get the source code of the functions\n",
        "run_models_source = inspect.getsource(run_models)\n",
        "evaluate_model_on_test_source = inspect.getsource(evaluate_model_on_test)\n",
        "\n",
        "# Combine the source code\n",
        "models_module_content = run_models_source + \"\\n\" + evaluate_model_on_test_source\n",
        "\n",
        "# Write the content to the file\n",
        "with open(\"modules/models.py\", \"w\") as f:\n",
        "    f.write(models_module_content)\n",
        "\n",
        "print(\"Functions written to modules/models.py\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions written to modules/models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.models import run_models, evaluate_model_on_test\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "KOAfTYwx1n2B"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e761709f"
      },
      "source": [
        "## Đánh giá Naive Bayes\n",
        "Nhóm sử dụng mô hình MultinomialNB - Biến thể Naive Bayes dùng cho đặc trưng là tần suất(tần suất xuất hiện của từ), mô hình hoàn toàn phù hợp với vector đặc trưng được trích xuất từ BoW và TF-IDF\n",
        "\n",
        "Chỉ chạy Naive Bayes với 2 cách trích xuất đặc trưng là BoW và TF-IDF vì Naive Bayes không thể xử lý được giá trị âm từ đặc trưng được trích xuất từ TF-IDF GloVe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44146901",
        "outputId": "e08d5fb9-5c3b-46a5-96ab-6b990f2c04a9"
      },
      "source": [
        "# --- Đánh giá Naive Bayes ---\n",
        "nb_params_list = model_params['NaiveBayes']\n",
        "best_nb_bow_params = None\n",
        "best_nb_bow_accuracy = -1\n",
        "best_nb_tfidf_params = None\n",
        "best_nb_tfidf_accuracy = -1\n",
        "\n",
        "nb_bow_results = {}\n",
        "nb_tfidf_results = {}\n",
        "\n",
        "# Naive Bayes with BoW features\n",
        "print(\"\\n--- Running Naive Bayes on BoW features ---\")\n",
        "for params in nb_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_bow, ytr, Xva_bow, yva, Xte_bow, yte, {'NaiveBayes': params})\n",
        "    val_acc = results['NaiveBayes']['val_accuracy']\n",
        "    nb_bow_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_nb_bow_accuracy:\n",
        "        best_nb_bow_accuracy = val_acc\n",
        "        best_nb_bow_params = params\n",
        "        best_nb_bow_model = results['NaiveBayes']['model']\n",
        "\n",
        "# Naive Bayes with TF-IDF features\n",
        "print(\"\\n--- Running Naive Bayes on TF-IDF features ---\")\n",
        "for params in nb_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_tfidf, ytr, Xva_tfidf, yva, Xte_tfidf, yte, {'NaiveBayes': params})\n",
        "    val_acc = results['NaiveBayes']['val_accuracy']\n",
        "    nb_tfidf_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_nb_tfidf_accuracy:\n",
        "        best_nb_tfidf_accuracy = val_acc\n",
        "        best_nb_tfidf_params = params\n",
        "        best_nb_tfidf_model = results['NaiveBayes']['model']\n",
        "\n",
        "# Evaluate the best models on the test set\n",
        "print(\"\\n--- Mô hình NB với tham số tốt nhất trong các mô hình đã kiểm tra ---\")\n",
        "if best_nb_bow_model:\n",
        "    best_nb_bow_test_accuracy = evaluate_model_on_test(best_nb_bow_model, Xte_bow, yte, f\"Naive Bayes (BoW) Best Params: {best_nb_bow_params}\")\n",
        "    nb_bow_results[str(best_nb_bow_params)]['test_accuracy'] = best_nb_bow_test_accuracy\n",
        "if best_nb_tfidf_model:\n",
        "    best_nb_tfidf_test_accuracy = evaluate_model_on_test(best_nb_tfidf_model, Xte_tfidf, yte, f\"Naive Bayes (TF-IDF) Best Params: {best_nb_tfidf_params}\")\n",
        "    nb_tfidf_results[str(best_nb_tfidf_params)]['test_accuracy'] = best_nb_tfidf_test_accuracy\n",
        "\n",
        "# Store results for later overall comparison\n",
        "results_nb = {\n",
        "    'BoW': nb_bow_results,\n",
        "    'TF-IDF': nb_tfidf_results\n",
        "}"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Naive Bayes on BoW features ---\n",
            "\n",
            "Running with parameters: {'alpha': 0.1}\n",
            "Validation Accuracy: 0.77914537854157\n",
            "\n",
            "Running with parameters: {'alpha': 1.0}\n",
            "Validation Accuracy: 0.783790060380864\n",
            "\n",
            "Running with parameters: {'alpha': 0.5}\n",
            "Validation Accuracy: 0.7777519739897817\n",
            "\n",
            "--- Running Naive Bayes on TF-IDF features ---\n",
            "\n",
            "Running with parameters: {'alpha': 0.1}\n",
            "Validation Accuracy: 0.8014398513701811\n",
            "\n",
            "Running with parameters: {'alpha': 1.0}\n",
            "Validation Accuracy: 0.7756618671620994\n",
            "\n",
            "Running with parameters: {'alpha': 0.5}\n",
            "Validation Accuracy: 0.7928471899674873\n",
            "\n",
            "--- Mô hình NB với tham số tốt nhất trong các mô hình đã kiểm tra ---\n",
            "\n",
            "--- Đánh giá mô hình Naive Bayes (BoW) Best Params: {'alpha': 1.0} tốt nhất trên tập Test ---\n",
            "Test Accuracy: 0.7897157190635451\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81       712\n",
            "           1       0.69      0.73      0.71       176\n",
            "           2       0.91      0.69      0.79      1092\n",
            "           3       0.80      0.79      0.80      1362\n",
            "           4       0.66      0.85      0.74       212\n",
            "           5       0.74      0.80      0.76       706\n",
            "           6       0.91      0.87      0.89       246\n",
            "           7       0.68      0.91      0.78       278\n",
            "\n",
            "    accuracy                           0.79      4784\n",
            "   macro avg       0.77      0.81      0.78      4784\n",
            "weighted avg       0.80      0.79      0.79      4784\n",
            "\n",
            "\n",
            "--- Đánh giá mô hình Naive Bayes (TF-IDF) Best Params: {'alpha': 0.1} tốt nhất trên tập Test ---\n",
            "Test Accuracy: 0.7995401337792643\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       712\n",
            "           1       0.87      0.53      0.66       176\n",
            "           2       0.87      0.76      0.81      1092\n",
            "           3       0.73      0.86      0.79      1362\n",
            "           4       0.81      0.72      0.77       212\n",
            "           5       0.73      0.76      0.75       706\n",
            "           6       0.95      0.85      0.90       246\n",
            "           7       0.87      0.80      0.83       278\n",
            "\n",
            "    accuracy                           0.80      4784\n",
            "   macro avg       0.83      0.77      0.79      4784\n",
            "weighted avg       0.81      0.80      0.80      4784\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nhận xét Naive Bayes\n",
        "### Tổng quan mô hình\n",
        "Mô hình Naive Bayes đạt độ chính xác khoảng 79-80% trên tập kiểm thử, cho thấy khả năng phân loại khá tốt với dữ liệu văn bản đa lớp. Tuy nhiên, vì NB giả định các đặc trưng độc lập - điều này không hoàn toàn đúng trong ngữ cảnh ngôn ngữ nên độ chính xác này vẫn chưa phải tối ưu nhất(các mô hình khác có thể có độ chính xác cao hơn).\n",
        "\n",
        "Giá trị recall, precision, f1-score giữa các nhóm không đều tuy nhiên macro avg khoảng 0.79 chứng tỏ mô hình không quá lệch về các lớp có nhiều dữ liệu.\n",
        "\n",
        "### Tham số tốt nhất\n",
        "Nhóm sử dụng Accuracy trên tập validation để đánh giá xem với siêu tham số nào sẽ phù hợp nhất với mô hình Naive Bayes trên từng cách trích xuất đặc trưng khác nhau.\n",
        "\n",
        "Dựa vào kết quả, nhận thấy được với BoW thì tham số tốt hơn cho mô hình là alpha = 1, tuy nhiên với TF-IDF thì tham số alpha tốt hơn lại là 0.1\n",
        "\n",
        "Điều này là do BoW tạo ra đặc trưng thô, có thể có nhiều từ có count = 0. Tham số alpha = 1 giúp làm trơn mạnh tránh xác suất = 0 nên giúp mô hình đạt độ chính xác cao hơn. Còn đối với TF-IDF thì đặc trưng đã được chuẩn hóa theo trọng số, nên các xác suất không còn cực đoan như trong BoW nữa, dẫn đến không cần phải làm mượt quá nhiều từ tham số alpha."
      ],
      "metadata": {
        "id": "Aw-583slg0nJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Đánh giá Logistic Regression"
      ],
      "metadata": {
        "id": "eqv82imPoAsK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53e95ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490368b8-417f-4fb8-9cbd-42d78a83004b"
      },
      "source": [
        "# --- Đánh giá Logistic Regression ---\n",
        "lr_params_list = model_params['LogisticRegression']\n",
        "best_lr_bow_params = None\n",
        "best_lr_bow_accuracy = -1\n",
        "best_lr_tfidf_params = None\n",
        "best_lr_tfidf_accuracy = -1\n",
        "best_lr_glove_params = None\n",
        "best_lr_glove_accuracy = -1\n",
        "\n",
        "lr_bow_results = {}\n",
        "lr_tfidf_results = {}\n",
        "lr_glove_results = {}\n",
        "\n",
        "# Logistic Regression with BoW features\n",
        "print(\"\\n--- Running Logistic Regression on BoW features ---\")\n",
        "for params in lr_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_bow, ytr, Xva_bow, yva, Xte_bow, yte, {'LogisticRegression': params})\n",
        "    val_acc = results['LogisticRegression']['val_accuracy']\n",
        "    lr_bow_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_lr_bow_accuracy:\n",
        "        best_lr_bow_accuracy = val_acc\n",
        "        best_lr_bow_params = params\n",
        "        best_lr_bow_model = results['LogisticRegression']['model']\n",
        "\n",
        "# Logistic Regression with TF-IDF features\n",
        "print(\"\\n--- Running Logistic Regression on TF-IDF features ---\")\n",
        "for params in lr_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_tfidf, ytr, Xva_tfidf, yva, Xte_tfidf, yte, {'LogisticRegression': params})\n",
        "    val_acc = results['LogisticRegression']['val_accuracy']\n",
        "    lr_tfidf_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_lr_tfidf_accuracy:\n",
        "        best_lr_tfidf_accuracy = val_acc\n",
        "        best_lr_tfidf_params = params\n",
        "        best_lr_tfidf_model = results['LogisticRegression']['model']\n",
        "\n",
        "# Logistic Regression with GloVe features\n",
        "print(\"\\n--- Running Logistic Regression on GloVe features ---\")\n",
        "for params in lr_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_w2v, ytr, Xva_w2v, yva, Xte_w2v, yte, {'LogisticRegression': params})\n",
        "    val_acc = results['LogisticRegression']['val_accuracy']\n",
        "    lr_glove_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_lr_glove_accuracy:\n",
        "        best_lr_glove_accuracy = val_acc\n",
        "        best_lr_glove_params = params\n",
        "        best_lr_glove_model = results['LogisticRegression']['model']\n",
        "\n",
        "# Evaluate the best models on the test set\n",
        "print(\"\\n--- Evaluating Best Logistic Regression Models on Test Set ---\")\n",
        "if best_lr_bow_model:\n",
        "    best_lr_bow_test_accuracy = evaluate_model_on_test(best_lr_bow_model, Xte_bow, yte, f\"Logistic Regression (BoW) Best Params: {best_lr_bow_params}\")\n",
        "    lr_bow_results[str(best_lr_bow_params)]['test_accuracy'] = best_lr_bow_test_accuracy\n",
        "if best_lr_tfidf_model:\n",
        "    best_lr_tfidf_test_accuracy = evaluate_model_on_test(best_lr_tfidf_model, Xte_tfidf, yte, f\"Logistic Regression (TF-IDF) Best Params: {best_lr_tfidf_params}\")\n",
        "    lr_tfidf_results[str(best_lr_tfidf_params)]['test_accuracy'] = best_lr_tfidf_test_accuracy\n",
        "if best_lr_glove_model:\n",
        "    best_lr_glove_test_accuracy = evaluate_model_on_test(best_lr_glove_model, Xte_w2v, yte, f\"Logistic Regression (GloVe) Best Params: {best_lr_glove_params}\")\n",
        "    lr_glove_results[str(best_lr_glove_params)]['test_accuracy'] = best_lr_glove_test_accuracy\n",
        "\n",
        "# Store results for later overall comparison\n",
        "results_lr = {\n",
        "    'BoW': lr_bow_results,\n",
        "    'TF-IDF': lr_tfidf_results,\n",
        "    'GloVe': lr_glove_results\n",
        "}"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Logistic Regression on BoW features ---\n",
            "\n",
            "Running with parameters: {'C': 0.1, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.8555503947979564\n",
            "\n",
            "Running with parameters: {'C': 1.0, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.8518346493265211\n",
            "\n",
            "Running with parameters: {'C': 10.0, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.8432419879238272\n",
            "\n",
            "--- Running Logistic Regression on TF-IDF features ---\n",
            "\n",
            "Running with parameters: {'C': 0.1, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.7974918718067813\n",
            "\n",
            "Running with parameters: {'C': 1.0, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.8543892243381328\n",
            "\n",
            "Running with parameters: {'C': 10.0, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.8539247561542035\n",
            "\n",
            "--- Running Logistic Regression on GloVe features ---\n",
            "\n",
            "Running with parameters: {'C': 0.1, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.7552252670692058\n",
            "\n",
            "Running with parameters: {'C': 1.0, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.774500696702276\n",
            "\n",
            "Running with parameters: {'C': 10.0, 'max_iter': 1000}\n",
            "Validation Accuracy: 0.7803065490013934\n",
            "\n",
            "--- Evaluating Best Logistic Regression Models on Test Set ---\n",
            "\n",
            "--- Đánh giá mô hình Logistic Regression (BoW) Best Params: {'C': 0.1, 'max_iter': 1000} tốt nhất trên tập Test ---\n",
            "Test Accuracy: 0.8649665551839465\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91       712\n",
            "           1       0.88      0.69      0.77       176\n",
            "           2       0.87      0.87      0.87      1092\n",
            "           3       0.82      0.88      0.85      1362\n",
            "           4       0.89      0.81      0.85       212\n",
            "           5       0.83      0.83      0.83       706\n",
            "           6       0.97      0.90      0.93       246\n",
            "           7       0.94      0.89      0.92       278\n",
            "\n",
            "    accuracy                           0.86      4784\n",
            "   macro avg       0.89      0.85      0.87      4784\n",
            "weighted avg       0.87      0.86      0.87      4784\n",
            "\n",
            "\n",
            "--- Đánh giá mô hình Logistic Regression (TF-IDF) Best Params: {'C': 1.0, 'max_iter': 1000} tốt nhất trên tập Test ---\n",
            "Test Accuracy: 0.8559782608695652\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.90       712\n",
            "           1       0.91      0.64      0.75       176\n",
            "           2       0.87      0.86      0.86      1092\n",
            "           3       0.79      0.90      0.84      1362\n",
            "           4       0.92      0.78      0.85       212\n",
            "           5       0.82      0.81      0.82       706\n",
            "           6       0.98      0.87      0.92       246\n",
            "           7       0.94      0.84      0.89       278\n",
            "\n",
            "    accuracy                           0.86      4784\n",
            "   macro avg       0.89      0.82      0.85      4784\n",
            "weighted avg       0.86      0.86      0.86      4784\n",
            "\n",
            "\n",
            "--- Đánh giá mô hình Logistic Regression (GloVe) Best Params: {'C': 10.0, 'max_iter': 1000} tốt nhất trên tập Test ---\n",
            "Test Accuracy: 0.7834448160535117\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83       712\n",
            "           1       0.77      0.56      0.65       176\n",
            "           2       0.80      0.78      0.79      1092\n",
            "           3       0.73      0.81      0.77      1362\n",
            "           4       0.87      0.80      0.83       212\n",
            "           5       0.71      0.70      0.71       706\n",
            "           6       0.90      0.87      0.89       246\n",
            "           7       0.86      0.84      0.85       278\n",
            "\n",
            "    accuracy                           0.78      4784\n",
            "   macro avg       0.81      0.77      0.79      4784\n",
            "weighted avg       0.79      0.78      0.78      4784\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nhận xét Logistic Regression\n",
        "### Tổng quan mô hình\n",
        "Accuracy khoảng 85-87% cho BoW và TF-IDF là rất tốt, tuy nhiên với GloVe thì độ chính xác lại giảm đáng kể(khoảng 78%).\n",
        "Accuracy ≈ 0.86. LR hoạt động tốt với không gian đặc trưng thưa, có chiều cao như BoW và TF-IDF\n",
        "\n",
        "Với BoW và TF-IDF thì Precision/Recall/F1 đều cao (0.83-0.92) trên các lớp chính (0,2,3,5,6). Một số lớp nhỏ (1, 4, 7) có recall thấp hơn (0.6-0.8) do ít mẫu hoặc chồng chéo đặc trưng. Nhưng macro avg ≈ 0.85-0.87 là rất cân bằng mô hình học được các lớp chính và không quá lệch.\n",
        "\n",
        "Đối với GloVe: Độ chính xác giảm rõ rệt do ảnh hưởng của trung bình vector. Vì là một mô hình tuyến tính, có thể không tận dụng được đầy đủ các mối quan hệ ngữ nghĩa phi tuyến tính, phức tạp được nắm bắt bởi các embedding từ đặc như GloVe. Từ đó ta thấy Logistic Regression không phù hợp với phương pháp trích xuất đặc trưng GloVe.\n",
        "### Tham số tốt nhất\n",
        "\n",
        "Nhóm sử dụng Accuracy trên tập validation để đánh giá xem với siêu tham số nào sẽ phù hợp nhất với mô hình Logistic Regression trên từng cách trích xuất đặc trưng khác nhau.\n",
        "\n",
        "Dựa vào kết quả, nhận thấy được với BoW thì tham số tốt hơn cho mô hình là C = 0.1, TF-IDF = 1 và GloVe là 10.0.\n",
        "\n",
        "Tham số 'C' kiểm soát nghịch đảo của độ mạnh điều chỉnh (regularization strength). C nhỏ hơn có nghĩa là điều chỉnh mạnh hơn giúp ngăn chặn overfitting.\n",
        "\n",
        "Với BoW, đặc trưng là tần suất xuất hiện của từ dẫn dễ làm mô hình overfit lên từ phổ biến. Do đó ta cần điều chỉnh mạnh nên C = 0.1 là tối ưu.\n",
        "Với TF-IDF, vốn đã giảm trọng số các thuật ngữ phổ biến nên ít cần điều chỉnh hơn, C lớn hơn một tí(C = 1). Điều này cho thấy việc gán trọng số TF-IDF làm cho các đặc trưng quan trọng nổi bật và điều chỉnh mạnh có thể gây phản tác dụng.\n",
        "\n",
        "Với GloVe thì Logistic Regression cần regularization yếu hơn (C lớn) để tận dụng tối đa thông tin nhỏ trong vector. Tuy nhiên do tính chất của mô hình không phù hợp nên độ chính xác vẫn rất thấp."
      ],
      "metadata": {
        "id": "R9pJ0ZbwqwSW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a15bccd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "5355fb7f-aeed-4522-8a54-8d1c20692507"
      },
      "source": [
        "# --- Đánh giá SVM ---\n",
        "svm_params_list = model_params['SVM']\n",
        "best_svm_bow_params = None\n",
        "best_svm_bow_accuracy = -1\n",
        "best_svm_tfidf_params = None\n",
        "best_svm_tfidf_accuracy = -1\n",
        "best_svm_glove_params = None\n",
        "best_svm_glove_accuracy = -1\n",
        "\n",
        "svm_bow_results = {}\n",
        "svm_tfidf_results = {}\n",
        "svm_glove_results = {}\n",
        "\n",
        "# SVM with BoW features\n",
        "print(\"\\n--- Running SVM on BoW features ---\")\n",
        "for params in svm_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_bow, ytr, Xva_bow, yva, Xte_bow, yte, {'SVM': params})\n",
        "    val_acc = results['SVM']['val_accuracy']\n",
        "    svm_bow_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_svm_bow_accuracy:\n",
        "        best_svm_bow_accuracy = val_acc\n",
        "        best_svm_bow_params = params\n",
        "        best_svm_bow_model = results['SVM']['model']\n",
        "\n",
        "# SVM with TF-IDF features\n",
        "print(\"\\n--- Running SVM on TF-IDF features ---\")\n",
        "for params in svm_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_tfidf, ytr, Xva_tfidf, yva, Xte_tfidf, yte, {'SVM': params})\n",
        "    val_acc = results['SVM']['val_accuracy']\n",
        "    svm_tfidf_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_svm_tfidf_accuracy:\n",
        "        best_svm_tfidf_accuracy = val_acc\n",
        "        best_svm_tfidf_params = params\n",
        "        best_svm_tfidf_model = results['SVM']['model']\n",
        "\n",
        "# SVM with GloVe features\n",
        "print(\"\\n--- Running SVM on GloVe features ---\")\n",
        "for params in svm_params_list:\n",
        "    print(f\"\\nRunning with parameters: {params}\")\n",
        "    results = run_models(Xtr_w2v, ytr, Xva_w2v, yva, Xte_w2v, yte, {'SVM': params})\n",
        "    val_acc = results['SVM']['val_accuracy']\n",
        "    svm_glove_results[str(params)] = {'val_accuracy': val_acc} # Store with string key for display\n",
        "\n",
        "    if val_acc > best_svm_glove_accuracy:\n",
        "        best_svm_glove_accuracy = val_acc\n",
        "        best_svm_glove_params = params\n",
        "        best_svm_glove_model = results['SVM']['model']\n",
        "\n",
        "# Evaluate the best models on the test set\n",
        "print(\"\\n--- Evaluating Best SVM Models on Test Set ---\")\n",
        "if best_svm_bow_model:\n",
        "    best_svm_bow_test_accuracy = evaluate_model_on_test(best_svm_bow_model, Xte_bow, yte, f\"SVM (BoW) Best Params: {best_svm_bow_params}\")\n",
        "    svm_bow_results[str(best_svm_bow_params)]['test_accuracy'] = best_svm_bow_test_accuracy\n",
        "if best_svm_tfidf_model:\n",
        "    best_svm_tfidf_test_accuracy = evaluate_model_on_test(best_svm_tfidf_model, Xte_tfidf, yte, f\"SVM (TF-IDF) Best Params: {best_svm_tfidf_params}\")\n",
        "    svm_tfidf_results[str(best_svm_tfidf_params)]['test_accuracy'] = best_svm_tfidf_test_accuracy\n",
        "if best_svm_glove_model:\n",
        "    best_svm_glove_test_accuracy = evaluate_model_on_test(best_svm_glove_model, Xte_w2v, yte, f\"SVM (GloVe) Best Params: {best_svm_glove_params}\")\n",
        "    svm_glove_results[str(best_svm_glove_params)]['test_accuracy'] = best_svm_glove_test_accuracy\n",
        "\n",
        "# Store results for later overall comparison\n",
        "results_svm = {\n",
        "    'BoW': svm_bow_results,\n",
        "    'TF-IDF': svm_tfidf_results,\n",
        "    'GloVe': svm_glove_results\n",
        "}"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running SVM on BoW features ---\n",
            "\n",
            "Running with parameters: {'C': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8453320947515095\n",
            "\n",
            "Running with parameters: {'C': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8316302833255922\n",
            "\n",
            "--- Running SVM on TF-IDF features ---\n",
            "\n",
            "Running with parameters: {'C': 0.1}\n",
            "Validation Accuracy: 0.8539247561542035\n",
            "\n",
            "Running with parameters: {'C': 1.0}\n",
            "Validation Accuracy: 0.8520668834184858\n",
            "\n",
            "--- Running SVM on GloVe features ---\n",
            "\n",
            "Running with parameters: {'C': 0.1}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1444722077.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msvm_params_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nRunning with parameters: {params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXva_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXte_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0msvm_glove_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# Store with string key for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/modules/models.py\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m(Xtr, ytr, Xva, yva, Xte, yte, model_params)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0msvm_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msvm_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0myva_pred_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXva\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myva_pred_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5XkHDYgW6ry-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFL7LDCSKQGG"
      },
      "source": [
        "# Phân tích cho SVM trên tất cả các bộ đặc trưng và tham số\n",
        "\n",
        "print(\"Phân tích Mô hình SVM (Tham số Tốt nhất):\")\n",
        "print(\"--------------------------------------\")\n",
        "\n",
        "print(\"\\nTóm tắt Kết quả (Tham số Tốt nhất):\")\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "for feature_set, c_values in svm_results.items():\n",
        "    print(f\"\\nBộ đặc trưng: {feature_set}\")\n",
        "    best_c = list(c_values.keys())[0]\n",
        "    metrics = c_values[best_c]\n",
        "    print(f\"  Tham số tốt nhất (C) = {best_c}:\")\n",
        "    print(f\"  Độ chính xác Validation: {metrics['val_accuracy']:.4f}\")\n",
        "    print(f\"  Độ chính xác Test: {metrics['test_accuracy']:.4f}\")\n",
        "\n",
        "print(\"\\nGiải thích Kết quả:\")\n",
        "print(\"-------------------\")\n",
        "print(\"Linear SVM (LinearSVC) là một bộ phân loại tuyến tính mạnh mẽ, tìm một siêu phẳng để phân tách các lớp với margin lớn nhất. Nó nổi tiếng là hoạt động tốt với dữ liệu thưa có chiều cao như BoW và TF-IDF.\")\n",
        "print(\"Tham số 'C' là tham số điều chỉnh. C nhỏ hơn có nghĩa là điều chỉnh mạnh hơn, phạt kích thước margin để giảm overfitting. C lớn hơn có nghĩa là điều chỉnh yếu hơn, cho phép margin nhỏ hơn để phù hợp hơn với dữ liệu huấn luyện.\")\n",
        "print(\"Đối với BoW và TF-IDF, điều chỉnh mạnh hơn (C nhỏ hơn) nhìn chung hoạt động tốt hơn, điều này phổ biến trong không gian chiều cao để ngăn mô hình trở nên quá phức tạp và overfitting.\")\n",
        "print(\"Các cảnh báo hội tụ cho thấy quá trình tối ưu hóa cho LinearSVC có thể chưa đạt đến cực tiểu toàn cục trong số lần lặp mặc định. Tăng `max_iter` có thể dẫn đến kết quả tốt hơn một chút, đặc biệt đối với các giá trị C cao hơn, nơi ít điều chỉnh hơn cho phép các mô hình phức tạp hơn.\")\n",
        "print(\"Hiệu suất thấp hơn với GloVe embeddings, tương tự Logistic Regression, chỉ ra rằng một SVM tuyến tính có thể không phải là mô hình tốt nhất để tận dụng đầy đủ các mối quan hệ phi tuyến tính và thông tin ngữ nghĩa phong phú được nhúng trong các vector từ đặc.\")\n",
        "print(\"Một lần nữa, cách tiếp cận lấy trung bình được sử dụng cho vector câu với GloVe có thể góp phần làm giảm hiệu suất so với các phương pháp xem xét thứ tự từ hoặc ngữ cảnh rõ ràng hơn.\")\n",
        "\n",
        "print(\"\\nƯu điểm và Hạn chế của SVM cho Phân loại Văn bản:\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\"Ưu điểm:\")\n",
        "print(\"- Hiệu quả trong không gian chiều cao (như BoW/TF-IDF).\")\n",
        "print(\"- Tìm siêu phẳng phân tách tối ưu, thường dẫn đến khả năng tổng quát hóa tốt.\")\n",
        "print(\"- Ít bị kẹt ở cực tiểu cục bộ hơn so với một số phương pháp tối ưu hóa khác.\")\n",
        "print(\"Hạn chế:\")\n",
        "print(\"- Có thể tốn kém tính toán cho các tập dữ liệu lớn (mặc dù LinearSVC có khả năng mở rộng tốt hơn kernel SVMs).\")\n",
        "print(\"- Hiệu suất có thể nhạy cảm với việc lựa chọn kernel và siêu tham số (như C).\")\n",
        "print(\"- Khó diễn giải hơn so với các mô hình như Naive Bayes hoặc Logistic Regression.\")\n",
        "print(\"- Linear SVM có thể không hoạt động tối ưu với các biểu diễn đặc trưng đặc, phức tạp như GloVe embeddings.\")\n",
        "print(\"- Các vấn đề hội tụ đôi khi có thể xảy ra, yêu cầu điều chỉnh tham số (ví dụ: max_iter).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "966c003c"
      },
      "source": [
        "# --- Overall Model and Embedding Comparison ---\n",
        "\n",
        "print(\"====================================================\")\n",
        "print(\" Overall Model and Embedding Comparison and Analysis\")\n",
        "print(\"====================================================\")\n",
        "\n",
        "print(\"\\nSummary of Best Test Accuracies:\")\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "# Extracting the best test accuracies for each model-embedding combination\n",
        "best_accuracies = {\n",
        "    'NaiveBayes': {\n",
        "        'BoW': results_nb['BoW'][str(best_nb_bow_params)]['test_accuracy'] if best_nb_bow_params else None,\n",
        "        'TF-IDF': results_nb['TF-IDF'][str(best_nb_tfidf_params)]['test_accuracy'] if best_nb_tfidf_params else None,\n",
        "        'GloVe': None # Naive Bayes not suitable for dense GloVe\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'BoW': results_lr['BoW'][str(best_lr_bow_params)]['test_accuracy'] if best_lr_bow_params else None,\n",
        "        'TF-IDF': results_lr['TF-IDF'][str(best_lr_tfidf_params)]['test_accuracy'] if best_lr_tfidf_params else None,\n",
        "        'GloVe': results_lr['GloVe'][str(best_lr_glove_params)]['test_accuracy'] if best_lr_glove_params else None\n",
        "    },\n",
        "    'SVM': {\n",
        "        'BoW': results_svm['BoW'][str(best_svm_bow_params)]['test_accuracy'] if best_svm_bow_params else None,\n",
        "        'TF-IDF': results_svm['TF-IDF'][str(best_svm_tfidf_params)]['test_accuracy'] if best_svm_tfidf_params else None,\n",
        "        'GloVe': results_svm['GloVe'][str(best_svm_glove_params)]['test_accuracy'] if best_svm_glove_params else None\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Model              | BoW      | TF-IDF   | GloVe\")\n",
        "print(\"-------------------|----------|----------|-------\")\n",
        "for model, embeddings in best_accuracies.items():\n",
        "    bow_acc = f\"{embeddings['BoW']:.4f}\" if embeddings['BoW'] is not None else 'N/A'\n",
        "    tfidf_acc = f\"{embeddings['TF-IDF']:.4f}\" if embeddings['TF-IDF'] is not None else 'N/A'\n",
        "    glove_acc = f\"{embeddings['GloVe']:.4f}\" if embeddings['GloVe'] is not None else 'N/A'\n",
        "    print(f\"{model:<18} | {bow_acc}   | {tfidf_acc}   | {glove_acc}\")\n",
        "\n",
        "print(\"\\nAnalysis of Model Effectiveness:\")\n",
        "print(\"------------------------------\")\n",
        "print(f\"- **Logistic Regression:** Achieved the highest overall accuracy with BoW features (~{best_accuracies['LogisticRegression']['BoW']:.4f if best_accuracies['LogisticRegression']['BoW'] is not None else 'N/A'}). It performed well with TF-IDF as well (~{best_accuracies['LogisticRegression']['TF-IDF']:.4f if best_accuracies['LogisticRegression']['TF-IDF'] is not None else 'N/A'}). Performance dropped significantly with GloVe (~{best_accuracies['LogisticRegression']['GloVe']:.4f if best_accuracies['LogisticRegression']['GloVe'] is not None else 'N/A'}). This suggests LR is highly effective with sparse, high-dimensional count/frequency-based features on this task.\")\n",
        "print(f\"- **SVM (LinearSVC):** Performed very competitively with Logistic Regression, achieving its best accuracy with TF-IDF (~{best_accuracies['SVM']['TF-IDF']:.4f if best_accuracies['SVM']['TF-IDF'] is not None else 'N/A'}) and a similar score with BoW (~{best_accuracies['SVM']['BoW']:.4f if best_accuracies['SVM']['BoW'] is not None else 'N/A'}). Like LR, its performance was much lower with GloVe (~{best_accuracies['SVM']['GloVe']:.4f if best_accuracies['SVM']['GloVe'] is not None else 'N/A'}). SVM is also well-suited for high-dimensional sparse data but didn't surpass LR significantly in peak performance on this dataset and with the tested parameters.\")\n",
        "print(f\"- **Naive Bayes (MultinomialNB):** Served as a good baseline, performing reasonably well with BoW (~{best_accuracies['NaiveBayes']['BoW']:.4f if best_accuracies['NaiveBayes']['BoW'] is not None else 'N/A'}) and slightly better with TF-IDF (~{best_accuracies['NaiveBayes']['TF-IDF']:.4f if best_accuracies['NaiveBayes']['TF-IDF'] is not None else 'N/A'}). It cannot be used with dense GloVe embeddings. While simpler and faster, its performance is noticeably lower than LR and SVM, likely due to its strong assumption of feature independence.\")\n",
        "print(\"\\nBased on the results, **Logistic Regression** or **Linear SVM** appear most suitable for this task among the tested models when using traditional embeddings (BoW/TF-IDF), with Logistic Regression slightly edging out in peak performance.\")\n",
        "\n",
        "print(\"\\nComparison of Embedding Effectiveness (BoW vs. TF-IDF vs. GloVe):\")\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(\"- **BoW:** Provided strong performance, especially for Logistic Regression. It captures term frequency and n-gram presence, which seems highly discriminative for this dataset.\")\n",
        "print(\"- **TF-IDF:** Also performed very well, often slightly better than BoW for Naive Bayes and very competitively for SVM and Logistic Regression. By weighting terms based on their inverse document frequency, it helps highlight more important/unique words.\")\n",
        "print(\"- **GloVe (TF-IDF Weighted Average):** Performed significantly worse than both BoW and TF-IDF across all models capable of using it (LR, SVM). This is a key observation that requires analysis.\")\n",
        "\n",
        "print(\"\\nPotential Reasons for GloVe's Lower Performance:\")\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"- **Model Suitability:** Linear models like Logistic Regression and Linear SVM might struggle to fully leverage the rich, non-linear semantic relationships captured by dense word embeddings like GloVe. They work best by finding linear separators in the feature space, which is more straightforward with the explicit word/ngram features of BoW/TF-IDF.\")\n",
        "print(\"- **Averaging Approach:** Averaging word vectors (even with TF-IDF weights) to represent a document can lead to a loss of information regarding word order, syntax, and the nuanced compositionality of meaning. Important local context might be diluted in the global average.\")\n",
        "print(\"- **Domain Mismatch:** The pre-trained GloVe embeddings were trained on general web data (Wikipedia + Gigaword). While they capture general language semantics, they might not effectively capture the specific terminology, jargon, and contextual nuances present in IT support tickets.\")\n",
        "print(\"- **Nature of the Task:** This text classification task might rely more on the presence of specific keywords, technical terms, and short phrases (captured well by BoW/TF-IDF n-grams) rather than deep semantic understanding of complex sentences (where dense embeddings typically shine).\")\n",
        "\n",
        "print(\"\\nAdvantages and Disadvantages based on Results:\")\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"- **BoW/TF-IDF:**\")\n",
        "print(\"  - **Advantages:** Simple, effective for capturing keyword presence and frequency, works well with linear models, computationally efficient for training/inference, interpretable (to some extent).\")\n",
        "print(\"  - **Disadvantages:** High dimensionality (especially with n-grams), sparsity issues, does not capture semantic relationships or word order, can be sensitive to vocabulary size.\")\n",
        "print(\"- **GloVe (TF-IDF Weighted Average):**\")\n",
        "print(\"  - **Advantages:** Captures some degree of semantic relationship between words (inherent from GloVe), fixed-size dense vector representation (independent of vocabulary size).\")\n",
        "print(\"  - **Disadvantages:** Performed poorly with linear models on this task, averaging may lose crucial information, potential domain mismatch with pre-trained embeddings, less interpretable than count-based methods.\")\n",
        "\n",
        "print(\"\\nConclusion and Best Approach:\")\n",
        "print(\"-----------------------------\")\n",
        "print(\"Based on the experimental results with Naive Bayes, Logistic Regression, and Linear SVM, the traditional count/frequency-based embeddings (**BoW** and **TF-IDF**) significantly outperformed the **TF-IDF weighted GloVe average** for this specific IT support ticket classification task.\")\n",
        "print(\"Among the models tested, **Logistic Regression with BoW features** achieved the highest accuracy. **Linear SVM with TF-IDF features** was a close second.\")\n",
        "print(\"For this problem and with these types of linear models, focusing on the explicit presence and importance of keywords and short phrases (captured by BoW/TF-IDF) seems more effective than relying on a simple average of general-purpose word embeddings.\")\n",
        "print(\"Further improvements might involve exploring other text representation techniques (e.g., character n-grams), trying non-linear models that can better utilize dense embeddings (e.g., Neural Networks), or using domain-specific embeddings if available.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f70ec5d7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because it tried to format `None` with a float format specifier. Fix this by ensuring the format specifier is only applied when the value is not `None`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb12bb62"
      },
      "source": [
        "## So sánh Mô hình và Phương pháp Embedding\n",
        "\n",
        "### Tóm tắt các kết quả Test Accuracy Tốt nhất:\n",
        "\n",
        "| Mô hình            | BoW    | TF-IDF | GloVe  |\n",
        "| :----------------- | :----- | :----- | :----- |\n",
        "| Naive Bayes        | {{best_accuracies['NaiveBayes']['BoW']:.4f}} | {{best_accuracies['NaiveBayes']['TF-IDF']:.4f}} | N/A    |\n",
        "| Logistic Regression| {{best_accuracies['LogisticRegression']['BoW']:.4f}} | {{best_accuracies['LogisticRegression']['TF-IDF']:.4f}} | {{best_accuracies['LogisticRegression']['GloVe']:.4f}} |\n",
        "| SVM                | {{best_accuracies['SVM']['BoW']:.4f}} | {{best_accuracies['SVM']['TF-IDF']:.4f}} | {{best_accuracies['SVM']['GloVe']:.4f}} |\n",
        "\n",
        "### Phân tích Hiệu quả của Mô hình:\n",
        "\n",
        "*   **Logistic Regression:** Đạt độ chính xác tổng thể cao nhất với đặc trưng BoW (~{{best_accuracies['LogisticRegression']['BoW']:.4f}}). Nó cũng hoạt động tốt với TF-IDF (~{{best_accuracies['LogisticRegression']['TF-IDF']:.4f}}). Tuy nhiên, hiệu suất giảm đáng kể với GloVe (~{{best_accuracies['LogisticRegression']['GloVe']:.4f}}). Điều này cho thấy LR rất hiệu quả với các đặc trưng thưa, có chiều cao dựa trên đếm/tần suất trong bài toán này.\n",
        "*   **SVM (LinearSVC):** Hoạt động rất cạnh tranh với Logistic Regression, đạt độ chính xác tốt nhất với TF-IDF (~{{best_accuracies['SVM']['TF-IDF']:.4f}}) và điểm tương tự với BoW (~{{best_accuracies['SVM']['BoW']:.4f}}). Giống như LR, hiệu suất của nó thấp hơn nhiều với GloVe (~{{best_accuracies['SVM']['GloVe']:.4f}}). SVM cũng phù hợp với dữ liệu thưa có chiều cao nhưng không vượt trội đáng kể so với LR về hiệu suất đỉnh trên tập dữ liệu này và với các tham số đã thử nghiệm.\n",
        "*   **Naive Bayes (MultinomialNB):** Đóng vai trò là một đường cơ sở tốt, hoạt động khá ổn với BoW (~{{best_accuracies['NaiveBayes']['BoW']:.4f}}) và hơi tốt hơn với TF-IDF (~{{best_accuracies['NaiveBayes']['TF-IDF']:.4f}}). Nó không thể sử dụng với các embedding đặc như GloVe. Mặc dù đơn giản và nhanh hơn, hiệu suất của nó thấp hơn đáng kể so với LR và SVM, có thể là do giả định mạnh mẽ về sự độc lập giữa các đặc trưng.\n",
        "\n",
        "Dựa trên kết quả, **Logistic Regression** hoặc **Linear SVM** có vẻ phù hợp nhất cho bài toán này trong số các mô hình đã thử nghiệm khi sử dụng các embedding truyền thống (BoW/TF-IDF), với Logistic Regression hơi nhỉnh hơn về hiệu suất đỉnh.\n",
        "\n",
        "### So sánh Hiệu quả của Phương pháp Embedding (BoW vs. TF-IDF vs. GloVe):\n",
        "\n",
        "*   **BoW:** Mang lại hiệu suất mạnh mẽ, đặc biệt cho Logistic Regression. Nó nắm bắt tần suất thuật ngữ và sự hiện diện của n-gram, điều này dường như rất phân biệt cho tập dữ liệu này.\n",
        "*   **TF-IDF:** Cũng hoạt động rất tốt, thường nhỉnh hơn BoW một chút đối với Naive Bayes và rất cạnh tranh đối với SVM và Logistic Regression. Bằng cách gán trọng số cho các thuật ngữ dựa trên tần suất tài liệu nghịch đảo của chúng, nó giúp làm nổi bật các từ quan trọng/độc đáo hơn.\n",
        "*   **GloVe (TF-IDF Weighted Average):** Hoạt động kém hơn đáng kể so với cả BoW và TF-IDF trên tất cả các mô hình có khả năng sử dụng nó (LR, SVM). Đây là một quan sát quan trọng cần phân tích.\n",
        "\n",
        "### Lý do Tiềm năng cho Hiệu suất Thấp hơn của GloVe:\n",
        "\n",
        "*   **Tính phù hợp của Mô hình:** Các mô hình tuyến tính như Logistic Regression và Linear SVM có thể gặp khó khăn trong việc tận dụng đầy đủ các mối quan hệ ngữ nghĩa phi tuyến tính, phức tạp được nắm bắt bởi các embedding từ đặc như GloVe. Chúng hoạt động tốt nhất bằng cách tìm các siêu phẳng phân tách tuyến tính trong không gian đặc trưng, điều này đơn giản hơn với các đặc trưng từ/n-gram rõ ràng của BoW/TF-IDF.\n",
        "*   **Phương pháp Lấy trung bình:** Việc lấy trung bình các vector từ (ngay cả với trọng số TF-IDF) để biểu diễn một văn bản có thể dẫn đến mất thông tin về thứ tự từ, cú pháp và tính cấu tạo nghĩa tinh tế. Ngữ cảnh cục bộ quan trọng có thể bị pha loãng trong giá trị trung bình tổng thể.\n",
        "*   **Không khớp Miền:** Các embedding GloVe tiền huấn luyện được huấn luyện trên dữ liệu web chung (Wikipedia + Gigaword). Mặc dù chúng nắm bắt ngữ nghĩa ngôn ngữ chung, nhưng có thể không hiệu quả trong việc nắm bắt các thuật ngữ cụ thể, biệt ngữ và sắc thái ngữ cảnh có trong các ticket hỗ trợ IT.\n",
        "*   **Bản chất của Bài toán:** Bài toán phân loại văn bản này có thể dựa nhiều hơn vào sự hiện diện của các từ khóa cụ thể, thuật ngữ kỹ thuật và cụm từ ngắn (được BoW/TF-IDF n-gram nắm bắt tốt) hơn là hiểu biết ngữ nghĩa sâu sắc về các câu phức tạp (nơi các embedding đặc thường phát huy tác dụng).\n",
        "\n",
        "### Ưu điểm và Nhược điểm dựa trên Kết quả:\n",
        "\n",
        "*   **BoW/TF-IDF:**\n",
        "    *   **Ưu điểm:** Đơn giản, hiệu quả trong việc nắm bắt sự hiện diện và tần suất từ khóa, hoạt động tốt với các mô hình tuyến tính, hiệu quả tính toán cho huấn luyện/suy luận, có thể diễn giải (ở mức độ nào đó).\n",
        "    *   **Nhược điểm:** Chiều cao (đặc biệt với n-grams), vấn đề thưa thớt, không nắm bắt mối quan hệ ngữ nghĩa hoặc thứ tự từ, có thể nhạy cảm với kích thước từ vựng.\n",
        "*   **GloVe (TF-IDF Weighted Average):**\n",
        "    *   **Ưu điểm:** Nắm bắt được mức độ nào đó mối quan hệ ngữ nghĩa giữa các từ (vốn có từ GloVe), biểu diễn vector đặc có kích thước cố định (không phụ thuộc vào kích thước từ vựng).\n",
        "    *   **Nhược điểm:** Hoạt động kém với các mô hình tuyến tính trong bài toán này, việc lấy trung bình có thể làm mất thông tin quan trọng, tiềm năng không khớp miền với các embedding tiền huấn luyện, khó diễn giải hơn so với các phương pháp dựa trên đếm.\n",
        "\n",
        "### Kết luận và Cách tiếp cận Tốt nhất:\n",
        "\n",
        "Dựa trên kết quả thực nghiệm với Naive Bayes, Logistic Regression và Linear SVM, các phương pháp embedding dựa trên đếm/tần suất truyền thống (**BoW** và **TF-IDF**) đã vượt trội đáng kể so với **TF-IDF weighted GloVe average** cho bài toán phân loại ticket hỗ trợ IT cụ thể này.\n",
        "\n",
        "Trong số các mô hình đã thử nghiệm, **Logistic Regression với đặc trưng BoW (cụ thể C=0.1)** đạt độ chính xác cao nhất. **Linear SVM với đặc trưng TF-IDF (cụ thể C=0.1)** xếp thứ hai sát nút.\n",
        "\n",
        "Đối với bài toán này và với các loại mô hình tuyến tính này, việc tập trung vào sự hiện diện rõ ràng và tầm quan trọng của các từ khóa và cụm từ ngắn (được BoW/TF-IDF nắm bắt) dường như hiệu quả hơn là dựa vào giá trị trung bình đơn giản của các embedding từ mục đích chung.\n",
        "\n",
        "Các cải tiến tiếp theo có thể bao gồm khám phá các kỹ thuật biểu diễn văn bản khác (ví dụ: n-gram ký tự), thử các mô hình phi tuyến tính có thể tận dụng tốt hơn các embedding đặc (ví dụ: Mạng nơ-ron), hoặc sử dụng các embedding dành riêng cho miền nếu có sẵn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiZ-79DvKeOr"
      },
      "source": [
        "# Code to extract best accuracies (keep this part)\n",
        "best_accuracies = {\n",
        "    'NaiveBayes': {\n",
        "        'BoW': results_nb_bow[max(results_nb_bow, key=lambda k: results_nb_bow[k]['test_accuracy'])]['test_accuracy'],\n",
        "        'TF-IDF': results_nb_tfidf[max(results_nb_tfidf, key=lambda k: results_nb_tfidf[k]['test_accuracy'])]['test_accuracy'],\n",
        "        'GloVe': None # Naive Bayes not suitable for dense GloVe\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'BoW': lr_results['BoW'][max(lr_results['BoW'], key=lambda k: lr_results['BoW'][k]['test_accuracy'])]['test_accuracy'],\n",
        "        'TF-IDF': lr_results['TF-IDF'][max(lr_results['TF-IDF'], key=lambda k: lr_results['TF-IDF'][k]['test_accuracy'])]['test_accuracy'],\n",
        "        'GloVe': lr_results['GloVe'][max(lr_results['GloVe'], key=lambda k: lr_results['GloVe'][k]['test_accuracy'])]['test_accuracy']\n",
        "    },\n",
        "    'SVM': {\n",
        "        'BoW': svm_results['BoW'][max(svm_results['BoW'], key=lambda k: svm_results['BoW'][k]['test_accuracy'])]['test_accuracy'],\n",
        "        'TF-IDF': svm_results['TF-IDF'][max(svm_results['TF-IDF'], key=lambda k: svm_results['TF-IDF'][k]['test_accuracy'])]['test_accuracy'],\n",
        "        'GloVe': svm_results['GloVe'][max(svm_results['GloVe'], key=lambda k: svm_results['GloVe'][k]['test_accuracy'])]['test_accuracy']\n",
        "    }\n",
        "}\n",
        "\n",
        "# The analysis will be moved to a markdown cell"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}