{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangHungLN/MachineLearning_Assignment/blob/main/Assignment1/notebooks/Assignment1_CEML2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "f-0czfmWnfzM",
        "outputId": "2d1d054d-610e-4d31-afeb-e8d2c86f433f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-29 04:14:31--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Assignment1/modules/__init__.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456 [text/plain]\n",
            "Saving to: ‘modules/__init__.py’\n",
            "\n",
            "\rmodules/__init__.py   0%[                    ]       0  --.-KB/s               \rmodules/__init__.py 100%[===================>]     456  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-29 04:14:31 (8.55 MB/s) - ‘modules/__init__.py’ saved [456/456]\n",
            "\n",
            "--2025-10-29 04:14:31--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Assignment1/modules/feature_extractors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5228 (5.1K) [text/plain]\n",
            "Saving to: ‘modules/feature_extractors.py’\n",
            "\n",
            "modules/feature_ext 100%[===================>]   5.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-29 04:14:31 (51.4 MB/s) - ‘modules/feature_extractors.py’ saved [5228/5228]\n",
            "\n",
            "--2025-10-29 04:14:31--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment1/modules/model_runner.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3780 (3.7K) [text/plain]\n",
            "Saving to: ‘modules/model_runner.py’\n",
            "\n",
            "modules/model_runne 100%[===================>]   3.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-29 04:14:31 (38.4 MB/s) - ‘modules/model_runner.py’ saved [3780/3780]\n",
            "\n",
            "--2025-10-29 04:14:33--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assingment/refs/heads/main/Assignment1/data/mobiles_uncleaned.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-10-29 04:14:34 ERROR 404: Not Found.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "No columns to parse from file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1960302340.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assingment/refs/heads/main/Assignment1/data/mobiles_uncleaned.csv -O data/mobiles_uncleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/mobiles_uncleaned.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34mr'â€‰'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\u2009'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ],
      "source": [
        "##Xử lý dữ liệu\n",
        "\n",
        "#Import thư viện\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "#Cấu hình style cho biểu đồ\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "sns.set_palette(\"Set2\")\n",
        "\n",
        "#Tải module từ github về colab\n",
        "!mkdir modules\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Assignment1/modules/__init__.py -O modules/__init__.py\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Assignment1/modules/feature_extractors.py -O modules/feature_extractors.py\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assigment/refs/heads/main/Assignment1/modules/model_runner.py -O modules/model_runner.py\n",
        "\n",
        "#Import các hàm trong feature_extractors va model_runner\n",
        "from modules.model_runner import *\n",
        "from modules.feature_extractors import *\n",
        "\n",
        "#Tải dữ liệu bảng CSV từ github\n",
        "!mkdir data\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Assignment1/data/mobiles_uncleaned.csv -O data/mobiles_uncleaned.csv\n",
        "raw_data = pd.read_csv(\"data/mobiles_uncleaned.csv\")\n",
        "raw_data.replace({r'â€‰':'', r'\\u2009': ''}, regex=True, inplace=True)\n",
        "\n",
        "#In thử 5 dòng đầu\n",
        "raw_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UODTrwaV1yPX"
      },
      "outputs": [],
      "source": [
        "  #Kiểm tra số lượng mẫu và thuộc tính gốc của dữ liệu\n",
        "  print(\"Số lượng mẫu có trong dataset là:\", raw_data.shape[0])\n",
        "  print(\"Số lượng thuộc tính có trong dataset là:\", raw_data.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGirN-8J1x7I"
      },
      "source": [
        "Trong bộ dữ liệu này, các thuộc tính bị thiếu được kí hiệu là NULL, sau đây nhóm em sẽ tiến hành chuyển dữ liệu thiếu thành NaN để dễ thống kê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BYTpZ3dTdpA6"
      },
      "outputs": [],
      "source": [
        "#Thay toàn bộ NULL thành NaN, thống kê missing value\n",
        "raw_data.replace(\"NULL\", np.nan, inplace=True)\n",
        "missing_count = raw_data.isna().sum()\n",
        "print(missing_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5F8RH_e2Un"
      },
      "source": [
        "Để trực quan hóa thì nhóm sẽ tạo dữ liệu dạng bảng để thống kê các giá trị bị thiếu\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBJttVkCfA5U",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Tính missing_rate cho từng cột\n",
        "missing_rate = (missing_count / len(raw_data) * 100).round(2)\n",
        "missing_data = pd.DataFrame({'Missing Count': missing_count, 'Missing Rate': missing_rate}).sort_values(by='Missing Rate', ascending=False)\n",
        "missing_data.index.name = 'Feature'\n",
        "#In ra bảng thống kê missing value\n",
        "missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fpKKH-icmomF"
      },
      "outputs": [],
      "source": [
        "print (\"\\n-----------------------------------------------------------------------------------Describe (numeric)--------------------------------------------------------------------------------------------\")\n",
        "#Thống kê mô tả cho các cột numeric\n",
        "mum_summary = raw_data.describe().round(2).T.reset_index()\n",
        "mum_summary = mum_summary.rename(columns={'index': 'Feature'}).set_index('Feature')\n",
        "mum_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugIrm9D9rR_X"
      },
      "source": [
        "Khi chạy lệnh nêu các đặc trưng của các biến định lượng thì ra thấy được rằng\n",
        "\n",
        "\n",
        "1.   Về thuộc tính giá (price)\n",
        "\n",
        "  *   Giá trị trung bình của các điện thoại là 117187,61\n",
        "\n",
        "  *   Độ lệch chuẩn của thuộc tính khá lớn (23707,84) cho thấy dữ liệu phân tán mạnh, không tập trung xung quanh giá trị trung bình\n",
        "  \n",
        "  * Nhiều khả năng tồn tại giá trị ngoại lai với mức giá quá cao hoặc quá thấp,dẫn đến phân phối bị lệch và kéo giá trị trung bình lên khá cao so với giá trị trung vị 9490\n",
        "\n",
        "\n",
        "2.   Về thuộc tính điểm cấu hình (spec_score)\n",
        "\n",
        "  * Giá trị trung bình của điểm cấu hình là 51,94 điểm, trung vị là 58 điểm\n",
        "  * Độ lệch chuẩn là 26,66 được xem là khá lớn so với thang điểm 100, điều này có thấy dữ liệu trải rộng\n",
        "  *Nhìn chung, vì giá trị trung bình nhỏ hơn trung vị nên phân phối có xu hướng lệch trái, nhưng vẫn cần sử dụng đồ thij để trực quan hơn\n",
        "\n",
        "3. Về thuộc tính đánh giá của khách hàng (user_rating)\n",
        "* Giá trị trung bình của đánh giá người dùng là 4.18 trên thang điểm 5, với trung vị là 4,25\n",
        "* Độ lệch chuẩn nhỏ (0.48) cho thấy tập dữ liệu tập trung xung quanh giá trị trung bình\n",
        "* Phân phối nghiên về các giá trị cao cho thấy điện thoại trong tập dữ liệu nhận được nhiều đánh giá tích cực từ người dùng, ít khi bị điểm thấp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2ZwS8WjExohA"
      },
      "outputs": [],
      "source": [
        "#Thống kê mô tả cho các cột Categorical\n",
        "cat_summary = raw_data.describe(include='object').T.reset_index()  # transpose để cột thành hàng\n",
        "cat_summary = cat_summary.rename(columns={'index': 'Feature'}).set_index('Feature') #đổi tên cột index thành Feature\n",
        "print (\"\\n-----------------------------------------------------------------------------------Describe (categorical)--------------------------------------------------------------------------------------------\")\n",
        "cat_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKPX4fTq20Ua"
      },
      "source": [
        "Khi chạy thống kê mô tả của các biến định tính ta thấy rằng:\n",
        "* _name_ : có 11,468 giá trị duy nhất trên 11,786 dòng (gần như mỗi dòng là một model khác nhau). Điều này làm cột này không hữu ích để phân tích thống kê hoặc mô hình hóa (có thể bỏ hoặc chỉ dùng để tham khảo).\n",
        "\n",
        "* _connectivity_ : gồm 68 loại, trong đó phổ biến nhất là “Dual Sim, 3G, 4G, VoLTE, Wi-Fi” (≈ 2,554 bản ghi). Đây là một thuộc tính có thể mã hóa và sử dụng.\n",
        "\n",
        "* _cpu_ : có 1,461 loại, phổ biến nhất là “Quad Core, 1.3 GHz Processor” (~399 bản ghi). Tuy nhiên cột này có nhiều missing values (chỉ 9,629/11,786 bản ghi).\n",
        "\n",
        "* _ram_ : gồm 443 loại, phổ biến nhất “8 GB RAM, 128 GB inbuilt” (~1,143 bản ghi). Thuộc tính này khá chi tiết nhưng còn phân mảnh nhiều.\n",
        "\n",
        "* _battery_ : gồm 955 loại, phổ biến nhất “1000 mAh Battery” (~695 bản ghi). Có nhiều kiểu pin khác nhau, dữ liệu phân tán.\n",
        "\n",
        "* _display_ : gồm 1,751 loại, phổ biến nhất “2.4 inches, 240x320px Display” (~681 bản ghi). Đa dạng, có thể cần chuẩn hóa (inch + độ phân giải tách riêng).\n",
        "\n",
        "* _camera_ : gồm 1,142 loại, phổ biến nhất “0.3 MP Rear Camera” (~1,227 bản ghi). Dữ liệu có xu hướng cụ thể nhưng nhiều dạng trình bày khác nhau.\n",
        "\n",
        "* _expandable_ : gồm 31 loại, phổ biến nhất “Memory Card Supported, upto 32GB” (~2,261 bản ghi). Đây là một biến categorical khá gọn.\n",
        "\n",
        "* _os_ : gồm 184 loại, phổ biến nhất “Android v11” (~818 bản ghi). Có nhiều phiên bản Android khác nhau, cần chuẩn hóa nhóm.\n",
        "\n",
        "* _fm_radio_ : dữ liệu khá thiếu, chỉ 1,557 bản ghi có thông tin (toàn bộ là “No FM Radio”). Giá trị phân loại này không đa dạng.\n",
        "\n",
        "* _other_ : toàn bộ chỉ có một giá trị “Wi-Fi” → không có giá trị phân biệt, có thể bỏ khỏi mô hình\n",
        "\n",
        "Qua đây ta có nhận xét rằng: Các thuộc tính như tên sản phẩm (name), fm radio và other có thể cân nhắc để loại bỏ ra khỏi mô hình. Ngoài ra cần chuẩn hóa các thuộc tính khác để có thể đem lại kết quả tốt nhất khi huấn luyện mô hình"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYMRl8e2ZDHH"
      },
      "source": [
        "Nhóm em tiến hành vẽ các biểu đồ để nhận xét mối quan hệ giữa các biến"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AYxCRqBLzjDS"
      },
      "outputs": [],
      "source": [
        "# Lấy danh sách các cột dạng numerical\n",
        "num_cols = raw_data.select_dtypes(include='number').columns\n",
        "\n",
        "# Vẽ biểu đồ cho từng Numeric\n",
        "for col in num_cols:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12,4))  # 1 hàng 2 cột\n",
        "\n",
        "    # Histogram + KDE\n",
        "    # Vẽ histogram phân phối giá trị của cột + đường KDE (đường cong mật độ xác suất ước lượng)\n",
        "    sns.histplot(raw_data[col], kde=True, bins=30, ax=axes[0])\n",
        "    axes[0].set_title(f\"Histogram of {col}\")\n",
        "    axes[0].set_xlabel(col)\n",
        "    axes[0].set_ylabel(\"Frequency\")\n",
        "\n",
        "    # Boxplot\n",
        "    # Vẽ boxplot để phát hiện phân phối và outlier\n",
        "    sns.boxplot(x=raw_data[col], ax=axes[1])\n",
        "    axes[1].set_title(f\"Boxplot of {col}\")\n",
        "    axes[1].set_xlabel(col)\n",
        "\n",
        "    # Căn chỉnh layout cho đẹp\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLPdOAQ7b6C_"
      },
      "source": [
        "**Nhận xét và đánh giá biểu đồ**\n",
        "\n",
        "1. Price\n",
        "\n",
        "- Biểu đồ histogram cho thấy phân phối giá bị lệch phải mạnh, phần lớn các sản phẩm có giá tập trung ở mức thấp dưới 20,000, trong khi vẫn tồn tại một số mẫu có giá trị rất cao kéo dài đến gần 500,000.\n",
        "\n",
        "- Boxplot cho thấy sự xuất hiện của rất nhiều ngoại lai (outliers) ở mức giá cao, có thể do các dòng sản phẩm flagship hoặc do dữ liệu nhập liệu chưa đồng nhất.\n",
        "\n",
        "- Như vậy, biến giá không có phân phối chuẩn, tồn tại nhiều ngoại lai và cần được xử lý, ví dụ bằng biến đổi logarit hoặc phân loại thành các nhóm giá trị.\n",
        "\n",
        "2. Spec Score\n",
        "\n",
        "- Histogram cho thấy phân phối khá đồng đều, có nhiều cụm điểm nổi bật, phản ánh việc nhiều sản phẩm có cùng cấu hình nên nhận cùng mức điểm.\n",
        "\n",
        "- Boxplot thể hiện dữ liệu phân bố trong khoảng 20–80 là chủ yếu, không có nhiều ngoại lai.\n",
        "\n",
        "- Đây là biến tương đối ổn định, phản ánh được sự đa dạng từ điện thoại cấu hình thấp đến cao, có thể sử dụng trực tiếp cho mô hình.\n",
        "\n",
        "3. User Rating\n",
        "\n",
        "- Histogram cho thấy phân phối lệch trái, phần lớn các đánh giá tập trung trong khoảng 4–5 sao, thể hiện xu hướng người dùng thường cho điểm cao.\n",
        "\n",
        "- Boxplot xuất hiện một số ngoại lai ở mức 1–2 sao, phản ánh các trường hợp người dùng không hài lòng.\n",
        "\n",
        "- Như vậy, biến đánh giá người dùng có tính thiên lệch tích cực, cần được chuẩn hóa hoặc xem xét loại bỏ ngoại lai khi sử dụng trong mô hình dự báo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqVUuvzEb6ct"
      },
      "outputs": [],
      "source": [
        "# Lấy danh sách các cột dạng categorical\n",
        "cat_cols = raw_data.select_dtypes(exclude='number').columns\n",
        "\n",
        "# Vẽ biểu đồ cho từng cột categorical\n",
        "for col in cat_cols:\n",
        "    # Lấy top 10 giá trị phổ biến nhất cho gọn\n",
        "    value_counts = raw_data[col].value_counts().head(10)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14,5))  # 1 hàng, 2 cột\n",
        "\n",
        "    # Countplot\n",
        "    # Vẽ biểu đồ cột thể hiện số lượng (count) của từng giá trị trong top 10\n",
        "    sns.countplot(y=col,\n",
        "                  data=raw_data,\n",
        "                  order=value_counts.index,\n",
        "                  ax=axes[0])\n",
        "    axes[0].set_title(f\"Top 10 categories of {col}\")\n",
        "    axes[0].set_xlabel(\"Count\")\n",
        "    axes[0].set_ylabel(col)\n",
        "\n",
        "    # Pie chart\n",
        "    # Vẽ biểu đồ tròn cho thấy tỉ lệ phần trăm của top 10 giá trị phổ biến\n",
        "    axes[1].pie(value_counts, labels=value_counts.index, autopct='%1.1f%%')\n",
        "    axes[1].set_title(f\"Top 10 distribution of {col}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nhận xét và đánh giá biểu đồ**\n",
        "\n",
        "1. name\n",
        "\n",
        "- Có tới hơn 11.000 giá trị duy nhất, hầu như mỗi dòng dữ liệu là một model khác nhau.\n",
        "\n",
        "- Các sản phẩm phổ biến nhất chỉ xuất hiện 2–3 lần, chiếm tỷ trọng rất nhỏ.\n",
        "\n",
        "- Nhận xét: Biến này không mang nhiều giá trị phân tích vì quá phân tán, chỉ nên dùng để tham khảo hoặc loại bỏ trong mô hình dự báo.\n",
        "\n",
        "2. connectivity\n",
        "\n",
        "- Phổ biến nhất là Dual Sim, 3G, 4G, VoLTE, Wi-Fi (≈ 25,8%).\n",
        "\n",
        "- Dual Sim nói chung chiếm đa số, phản ánh đúng đặc điểm thị trường Ấn Độ với nhu cầu dùng nhiều SIM.\n",
        "\n",
        "- Nhận xét: Đây là biến quan trọng, có thể rút gọn thành nhóm (Single Sim vs Dual Sim, 3G/4G/5G) để tăng tính khái quát.\n",
        "\n",
        "3. cpu\n",
        "\n",
        "- Loại phổ biến nhất: Quad Core, 1.3 GHz Processor (~23%).\n",
        "\n",
        "- Ngoài ra có nhiều biến thể nhỏ lẻ (Octa Core, Snapdragon 8 Gen2, v.v.).\n",
        "\n",
        "- Nhận xét: Dữ liệu CPU bị phân mảnh, cần chuẩn hóa thành các nhóm (Single, Dual, Quad, Octa, Deca) và tốc độ (GHz) để phân tích tốt hơn.\n",
        "\n",
        "4. ram\n",
        "\n",
        "- Phổ biến nhất: 8GB RAM, 128GB inbuilt (~17%).\n",
        "\n",
        "- Các cấu hình phổ biến tập trung quanh 4GB–8GB RAM, phản ánh mặt bằng chung của smartphone tầm trung.\n",
        "\n",
        "- Nhận xét: Đây là biến hữu ích, có thể tách thành hai cột độc lập: RAM và ROM để phân tích sâu.\n",
        "\n",
        "5. battery\n",
        "\n",
        "- Phổ biến nhất: 1000 mAh và 3000 mAh.\n",
        "\n",
        "- Tuy nhiên, nhiều mẫu mới có pin 4000–5000 mAh, thậm chí kèm sạc nhanh.\n",
        "\n",
        "- Nhận xét: Cần chuẩn hóa thành biến số (battery capacity, fast charging yes/no) để khai thác giá trị.\n",
        "\n",
        "6. display\n",
        "\n",
        "- Loại phổ biến nhất: 2.4 inches, 240x320px (~23,5%).\n",
        "\n",
        "- Có sự phân hóa rõ rệt: nhiều mẫu điện thoại phổ thông (2–3 inch) và smartphone hiện đại (5–6.7 inch).\n",
        "\n",
        "- Nhận xét: Cần tách thông tin thành kích thước (inch), độ phân giải (px) và tần số quét (Hz) để phân tích.\n",
        "\n",
        "7. camera\n",
        "\n",
        "- Phổ biến nhất: 0.3 MP Rear Camera (~28%).\n",
        "\n",
        "- Ngoài ra có nhiều kết hợp rear + front camera khác nhau.\n",
        "\n",
        "- Nhận xét: Đây là biến quan trọng nhưng cần chuẩn hóa: chia thành rear camera MP và front camera MP.\n",
        "\n",
        "8. expandable\n",
        "\n",
        "- Phổ biến nhất: Memory Card Supported, upto 32GB (~27%).\n",
        "\n",
        "- Khoảng 13% không hỗ trợ thẻ nhớ.\n",
        "\n",
        "- Nhận xét: Biến này đơn giản, có thể rút thành boolean (có/không hỗ trợ) + dung lượng tối đa.\n",
        "\n",
        "9. os\n",
        "\n",
        "- Phổ biến nhất: Android v11 (~15%).\n",
        "\n",
        "- Dữ liệu tập trung chủ yếu ở Android từ v9 đến v14.\n",
        "\n",
        "- Nhận xét: Đây là biến hữu ích, nhưng cần chuẩn hóa thành số (phiên bản chính) để dùng trong mô hình.\n",
        "\n",
        "10. fm_radio\n",
        "\n",
        "- Toàn bộ giá trị là No FM Radio.\n",
        "\n",
        "- Nhận xét: Biến này không mang thông tin phân biệt → có thể loại bỏ khỏi tập dữ liệu.\n",
        "\n",
        "11. other\n",
        "\n",
        "- Toàn bộ dữ liệu chỉ có một giá trị duy nhất: Wi-Fi (chiếm 100%).\n",
        "\n",
        "- Nhận xét: Biến này hoàn toàn không mang tính phân biệt, không đóng góp thêm thông tin cho mô hình. Do đó, có thể loại bỏ khỏi tập dữ liệu để giảm nhiễu và tránh thừa biến."
      ],
      "metadata": {
        "id": "wxxBgoKmKKtr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbMHyoLccIsT"
      },
      "outputs": [],
      "source": [
        "# Tính ma trận tương quan (correlation matrix) giữa các cột numeric\n",
        "corr = raw_data[num_cols].corr()\n",
        "\n",
        "# Vẽ heatmap để trực quan hóa mối quan hệ\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr,\n",
        "            annot=True,       # hiện giá trị hệ số tương quan\n",
        "            cmap=\"coolwarm\",  # bảng màu xanh-đỏ\n",
        "            fmt=\".2f\",        # 2 chữ số thập phân\n",
        "            linewidths=0.5,   # khoảng cách giữa các ô\n",
        "            cbar_kws={\"shrink\": 0.8})  # thu nhỏ thanh màu bên cạnh\n",
        "\n",
        "plt.title(\"Correlation Heatmap (Numeric Features)\", fontsize=14, pad=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nhận xét:**\n",
        "\n",
        "Do dữ liệu chỉ có rất ít biến numeric (price, spec_score, user_rating), nên heatmap này không thể hiện được nhiều thông tin. Có thể thấy price tương quan mức trung bình với spec_score (0.60) và khá thấp với user_rating (0.20). Tuy nhiên, nhìn chung, số lượng biến quá ít nên heatmap này chỉ mang tính tham khảo, không rút ra được nhiều kết luận."
      ],
      "metadata": {
        "id": "BdDcm0hmPd_y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LodKjjUAsu0O"
      },
      "source": [
        "Tiền xử lý dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAqKBppFdJGm"
      },
      "outputs": [],
      "source": [
        "#Tách ra các đặc trưng mới\n",
        "raw_data['battery_num'] = raw_data['battery'].apply(extract_battery)\n",
        "raw_data['fast_charging'] = raw_data['battery'].apply(extract_fast_charging)\n",
        "raw_data['ram_num'] = raw_data['ram'].apply(extract_ram)\n",
        "raw_data['rom_num'] = raw_data['ram'].apply(extract_rom)\n",
        "raw_data['screen_size'] = raw_data['display'].apply(extract_screen_size)\n",
        "raw_data['refresh_rate'] = raw_data['display'].apply(extract_refresh_rate)\n",
        "raw_data['ppi'] = raw_data['display'].apply(extract_ppi)\n",
        "raw_data['rear_camera_prio'] = raw_data['camera'].apply(extract_rear)\n",
        "raw_data['front_camera_prio'] = raw_data['camera'].apply(extract_front_camera)\n",
        "raw_data['expandable_storage'] = raw_data['expandable'].apply(extract_expandable_storage)\n",
        "raw_data['os'] = raw_data['os'].apply(extract_os)\n",
        "raw_data['cpu_brand'] = raw_data['cpu'].apply(extract_cpu_brand)\n",
        "raw_data['cpu_speed'] = raw_data['cpu'].apply(extract_cpu_speed)\n",
        "raw_data['cpu_core'] = raw_data['cpu'].apply(extract_cpu_core)\n",
        "raw_data['is_5g'] = raw_data['connectivity'].apply(extract_is_5g)\n",
        "raw_data['is_dual_sim'] = raw_data['connectivity'].apply(extract_is_dual_sim)\n",
        "raw_data['is_nfc'] = raw_data['connectivity'].apply(extract_is_nfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGOcsO2QeAzs"
      },
      "outputs": [],
      "source": [
        "#Tính missing ratio\n",
        "missing_ratio = (raw_data.isna().sum())/raw_data.shape[0] *100\n",
        "print(missing_ratio)\n",
        "\n",
        "# Giữ lại các cột quan trọng cho mô hình, loại bỏ cột không cần thiết\n",
        "keep_col = ['price', 'name', 'spec_score', 'user_rating','battery_num', 'fast_charging', 'ram_num', 'rom_num', 'os', 'screen_size', 'ppi', 'rear_camera_prio',\n",
        "            'front_camera_prio', 'expandable_storage', 'cpu_brand', 'cpu_speed', 'cpu_core', 'is_5g', 'is_dual_sim', 'is_nfc']\n",
        "raw_data = raw_data[keep_col] #dữ liệu sau khi bỏ bớt các đặc trưng không cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CN2LeUxcxKBg"
      },
      "outputs": [],
      "source": [
        "# Danh sách các cột số cần kiểm tra outlier\n",
        "num_feature = ['spec_score','ppi','ram_num','rom_num','cpu_speed', 'cpu_core', 'rear_camera_prio','front_camera_prio',\n",
        "               'user_rating', 'battery_num', 'expandable_storage', 'screen_size', 'fast_charging', 'is_5g', 'is_dual_sim', 'is_nfc']\n",
        "cat_feature = ['cpu_brand','os']\n",
        "\n",
        "# Hàm phát hiện outlier dựa vào quy tắc IQR\n",
        "def detect_outliers_iqr(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    return series[(series < lower) | (series > upper)]\n",
        "\n",
        "# Kiểm tra từng cột\n",
        "for col in num_feature:\n",
        "    outliers = detect_outliers_iqr(raw_data[col])\n",
        "    print(f\"Number of outliers in {col}: {len(outliers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MbsXFcZa28yb"
      },
      "outputs": [],
      "source": [
        "df_log = raw_data.copy()\n",
        "\n",
        "# Log transform biến nhiều outlier\n",
        "for col in ['price', 'user_rating', 'expandable_storage', 'front_camera_prio', 'rom_num', 'ram_num']:\n",
        "    df_log[col + '_log'] = np.log1p(raw_data[col])  # log(1+x) để tránh log(0)\n",
        "\n",
        "# Vẽ so sánh\n",
        "fig, axes = plt.subplots(6, 2, figsize=(12, 10))\n",
        "\n",
        "for i, col in enumerate(['price', 'user_rating', 'expandable_storage', 'front_camera_prio', 'rom_num', 'ram_num']):\n",
        "    # Histogram gốc\n",
        "    axes[i,0].hist(raw_data[col].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
        "    axes[i,0].set_title(f\"Original {col}\")\n",
        "\n",
        "    # Histogram log\n",
        "    axes[i,1].hist(df_log[col + '_log'].dropna(), bins=50, color='salmon', edgecolor='black')\n",
        "    axes[i,1].set_title(f\"Log-transformed {col}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "raw_data['user_rating'] = df_log['user_rating_log']\n",
        "raw_data['expandable_storage'] = df_log['expandable_storage_log']\n",
        "raw_data['front_camera_prio'] = df_log['front_camera_prio_log']\n",
        "raw_data['rom_num'] = df_log['rom_num_log']\n",
        "raw_data['ram_num'] = df_log['ram_num_log']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nhận xét:**\n",
        "\n",
        "1. Price\n",
        "\n",
        "- Trước log: phân phối lệch phải mạnh, nhiều giá trị nhỏ, một số rất lớn kéo dài đuôi phải.\n",
        "\n",
        "- Sau log: dữ liệu trở nên gần chuẩn, đối xứng hơn, tập trung quanh giá trị trung bình.\n",
        "\n",
        "- Log-transform cải thiện rõ rệt, giảm ảnh hưởng outlier.\n",
        "\n",
        "2. User_rating\n",
        "\n",
        "- Trước log: phân phối tập trung cao ở mức 4–5 điểm, lệch phải nhẹ, ít giá trị thấp.\n",
        "\n",
        "- Sau log: phân phối dịch sang trái, bớt lệch nhưng không thay đổi bản chất (vẫn tập trung cao ở một khoảng hẹp).\n",
        "\n",
        "- Log-transform không đem lại nhiều ý nghĩa vì bản thân dữ liệu đã ít outlier.\n",
        "\n",
        "3. Expandable_storage\n",
        "\n",
        "- Trước log: phân phối rời rạc, nhiều cụm giá trị (0, 512MB, 1GB, 2GB, …).\n",
        "\n",
        "- Sau log: dữ liệu nén lại, phân bố đều hơn giữa các mức.\n",
        "\n",
        "- Log-transform giúp rõ ràng hơn nhưng dữ liệu vốn mang tính discrete nên hiệu quả hạn chế.\n",
        "\n",
        "4. Front_camera_prio\n",
        "\n",
        "- Trước log: phân phối nhiều đỉnh (multimodal), rời rạc.\n",
        "\n",
        "- Sau log: dữ liệu co cụm hơn, phân bố mượt hơn.\n",
        "\n",
        "- Log-transform cải thiện phần nào, nhưng bản chất dữ liệu discrete nên không hoàn toàn chuẩn hóa được.\n",
        "\n",
        "5. Rom_num\n",
        "\n",
        "- Trước log: lệch phải rất mạnh, nhiều giá trị nhỏ, một số cực lớn.\n",
        "\n",
        "- Sau log: phân phối gần chuẩn, cân đối hơn.\n",
        "\n",
        "- Log-transform hữu ích rõ rệt.\n",
        "\n",
        "6. Ram_num\n",
        "\n",
        "- Trước log: lệch phải, nhiều giá trị thấp, một số giá trị cao kéo dài đuôi phải.\n",
        "\n",
        "- Sau log: dữ liệu trở nên phân bố đều hơn, giảm lệch.\n",
        "\n",
        "- Log-transform hiệu quả.\n",
        "\n",
        "**Kết luận:**\n",
        "\n",
        "- Các biến có giá trị lệch mạnh và nhiều outlier như price, ram_num, rom_num được cải thiện rõ rệt sau log-transform, phân phối trở nên gần chuẩn, giúp mô hình học tốt hơn.\n",
        "\n",
        "- Một số biến rời rạc/discrete như expandable_storage, front_camera_prio được nén lại nhưng vẫn còn đặc trưng nhảy bậc.\n",
        "\n",
        "- Biến user_rating vốn đã phân phối hẹp, log-transform không thay đổi nhiều, có thể cân nhắc giữ nguyên."
      ],
      "metadata": {
        "id": "jHxo8WBdOe72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYbWfkvTeOii"
      },
      "outputs": [],
      "source": [
        "#Chia target(price) thành biến phân loại để áp dụng các mô hình: Logistic Regression, SVM, Random Forest\n",
        "low_threshold = raw_data['price'].quantile(0.25)\n",
        "high_threshold = raw_data['price'].quantile(0.75)\n",
        "\n",
        "def categorize_price(price):\n",
        "    if price <= low_threshold:\n",
        "        return 'low'\n",
        "    elif price <= high_threshold:\n",
        "        return 'medium'\n",
        "    else:\n",
        "        return 'high'\n",
        "raw_data['price_category'] = raw_data['price'].apply(categorize_price)\n",
        "target = 'price_category'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1qrq01clwqd"
      },
      "source": [
        "Bắt đầu phần 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8h-w0s83mRz"
      },
      "outputs": [],
      "source": [
        "cleaned_data = raw_data.copy()\n",
        "# Tính ma trận tương quan cho các biến số\n",
        "num_feature_with_price = num_feature + ['price']\n",
        "corr = raw_data[num_feature_with_price].corr()\n",
        "\n",
        "# Vẽ heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr,\n",
        "            annot=True,       # hiện giá trị hệ số tương quan\n",
        "            cmap=\"coolwarm\",  # bảng màu xanh-đỏ\n",
        "            fmt=\".2f\",        # 2 chữ số thập phân\n",
        "            linewidths=0.5,   # khoảng cách giữa các ô\n",
        "            cbar_kws={\"shrink\": 0.8})  # thu nhỏ thanh màu bên cạnh\n",
        "\n",
        "plt.title(\"Correlation Heatmap (Numeric Features)\", fontsize=14, pad=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Nhóm có tương quan rất cao (≥ 0.9)\n",
        "\n",
        "- spec_score - ram_num (0.93), rom_num (0.94), cpu_speed (0.84), ppi (0.86), screen_size (0.96).\n",
        "\n",
        "- Điều này hợp lý: điểm cấu hình (spec_score) vốn được tính dựa trên RAM, ROM, CPU, màn hình… nên mối quan hệ chặt chẽ.\n",
        "\n",
        "- Rủi ro: multicollinearity, các biến này mang thông tin trùng lặp.\n",
        "\n",
        "2. Nhóm có tương quan trung bình (0.5 – 0.7)\n",
        "\n",
        "- spec_score - rear_camera_prio (0.71), front_camera_prio (0.81), fast_charging (0.78).\n",
        "\n",
        "- battery_num: ram_num (0.66), rom_num (0.64), screen_size (0.62).\n",
        "\n",
        "- Các yếu tố camera, pin, sạc nhanh có liên quan nhưng không phải thành phần chính trong điểm cấu hình.\n",
        "\n",
        "3. Nhóm có tương quan yếu (< 0.4)\n",
        "\n",
        "- user_rating - các biến còn lại (0.28 – 0.39).\n",
        "\n",
        "- expandable_storage hầu hết tương quan rất thấp (~0.2–0.3).\n",
        "\n",
        "- is_dual_sim, is_5g, is_nfc tương quan thấp với các biến khác (0.2–0.5).\n",
        "\n",
        "- Đây là các đặc trưng bổ sung, độc lập, có thể thêm giá trị riêng cho mô hình.\n",
        "\n",
        "4. Price (target)\n",
        "\n",
        "- price có mức tương quan trung bình (~0.55–0.60) với một số đặc trưng như ram_num, rom_num, spec_score.\n",
        "\n",
        "- Điều này hợp lý vì giá điện thoại ngoài cấu hình còn phụ thuộc vào thương hiệu, năm ra mắt, chính sách thị trường…, nên tương quan không quá cao.\n",
        "\n",
        "- Tuy nhiên, chính vì phản ánh thực tế khách quan, price được chọn làm target thay vì spec_score (vốn chỉ là điểm số tổng hợp từ các đặc trưng khác).\n",
        "\n",
        "5. Nhận xét tổng quát\n",
        "\n",
        "- Có sự đa cộng tuyến mạnh giữa spec_score và các biến cấu phần (ram_num, rom_num, cpu_speed, ppi, screen_size). Khi đưa vào mô hình tuyến tính cần chọn lọc, tránh đưa tất cả.\n",
        "\n",
        "- user_rating và expandable_storage ít tương quan → có thể giữ lại như yếu tố bổ sung.\n",
        "\n",
        "- Các biến nhị phân (is_5g, is_dual_sim, is_nfc) mang thông tin độc lập, không trùng lặp, nên hữu ích cho dự đoán.\n",
        "\n",
        "- price được giữ lại trong EDA để kiểm tra tương quan, nhưng khi train mô hình phải bỏ ra (target đã tách thành price_category)."
      ],
      "metadata": {
        "id": "8o29OhgkUHFK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX5Z1uWsO4g6"
      },
      "source": [
        "Do dữ liệu gồm các đặc trưng phân loại rời rạc (cpu_brand, os), không có thứ tự tự nhiên nên chỉ sử dụng One-Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mDfgDlH8w_h"
      },
      "source": [
        "Thử mô hình Logistic Regression với các cấu hình khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX5sOc-60Uc1"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "\n",
        "print (\"Các độ đo của mô hình LR với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 12 chiều:\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Logistic Regression với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 8 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=8,\n",
        ")\n",
        "\n",
        "print (\"Các độ đo của mô hình LR với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 8 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "#Logistic Regression với KNN Imputer với n_neighbors = 10, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=10,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình LR với KNN Imputer với n_neighbors = 10, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Logistic Regression với Simple Imputer sử dụng mean, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='mean',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình LR với Simple Imputer sử dụng mean, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Logistic Regression với Simple Imputer sử dụng median, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='median',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình LR với Simple Imputer sử dụng median, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Logistic Regression với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình LR với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Logistic Regression với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 10), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 10),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình LR với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 10), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Logistic Regression với Simple Imputer sử dụng mean, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=LogisticRegression(max_iter=500),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 10),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình LR với Simple Imputer sử dụng mean, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJbfOlsaGrEL"
      },
      "source": [
        "Thử mô hình SVC với các cấu hình khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNt1VjVt8vKe"
      },
      "outputs": [],
      "source": [
        "#SVC với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "\n",
        "print (\"Các độ đo của mô hình SVC với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 12 chiều:\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#SVC với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 8 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=8,\n",
        ")\n",
        "\n",
        "print (\"Các độ đo của mô hình SVC với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 8 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "#SVC với KNN Imputer với n_neighbors = 10, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=10,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình SVC với KNN Imputer với n_neighbors = 10, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#SVC với Simple Imputer sử dụng mean, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='mean',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình SVC với Simple Imputer sử dụng mean, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#SVC với Simple Imputer sử dụng median, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='median',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình SVC với Simple Imputer sử dụng median, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#SVC với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình SVC với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#SVC với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 10), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 10),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình SVC với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 10), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#SVC với Simple Imputer sử dụng mean, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=SVC(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 10),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình SVC với Simple Imputer sử dụng mean, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w85p7j6GH8GL"
      },
      "source": [
        "Thử mô hình Random Forest với các cấu hình khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDa2WBHS4g4E"
      },
      "outputs": [],
      "source": [
        "#Random Forest không cần encoder trước\n",
        "#Random Forest với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "\n",
        "print (\"Các độ đo của mô hình Random Forest với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 12 chiều:\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Random Forest với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 8 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=8,\n",
        ")\n",
        "\n",
        "print (\"Các độ đo của mô hình Random Forest với KNN Imputer với n_neighbors = 5, standard scaler, PCA giữ lại 8 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "#Random Forest với KNN Imputer với n_neighbors = 10, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=10,\n",
        "    imputer='knn',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình Random Forest với KNN Imputer với n_neighbors = 10, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Random Forest với Simple Imputer sử dụng mean, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='mean',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình Random Forest với Simple Imputer sử dụng mean, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Random Forest với Simple Imputer sử dụng median, standard scaler, PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='median',\n",
        "    scaler='standard',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình Random Forest với Simple Imputer sử dụng median, standard scaler, PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Random Forest với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 1),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình Random Forest với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Random Forest với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 10), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 10),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình Random Forest với KNN Imputer với n_neighbors = 5, minmax scaler với feature_range = (0, 10), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')\n",
        "\n",
        "#Random Forest với Simple Imputer sử dụng mean, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều\n",
        "metrics, pipe = run_model(\n",
        "    model=RandomForestClassifier(),\n",
        "    num_feature=num_feature,\n",
        "    cat_feature=cat_feature,\n",
        "    data=cleaned_data,\n",
        "    target='price_category',\n",
        "    feature_range=(0, 10),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    n_neighbors=5,\n",
        "    imputer='knn',\n",
        "    scaler='minmax',\n",
        "    n_components=12,\n",
        ")\n",
        "print (\"Các độ đo của mô hình Random Forest với Simple Imputer sử dụng mean, minmax scaler với feature_range = (0, 1), PCA giữ lại 12 chiều:\\n\")\n",
        "df = pd.DataFrame(metrics, index=[\"Score\"])\n",
        "print(df.T)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do dữ liệu của nhóm gồm các đặc trưng phân loại rời rạc (cpu_brand, os), không có thứ tự tự nhiên nên nhóm chỉ dùng One-Hot Encoding cho tất cả các mô hình, vì Label Encoding sẽ tạo ra thứ tự giả làm cho đặc trưng không còn ý nghĩa như ban đầu.\n",
        "**Nhận xét chi tiết và kết luận**\n",
        "\n",
        "**1. Logistic Regression (LR)**\n",
        "\n",
        "*So sánh KNN Imputer và Simple Imputer*\n",
        "\n",
        "- Với KNN Imputer (n_neighbors=5), mô hình đạt Accuracy ~0.862 (PCA=12), cao hơn rõ so với Simple Imputer (mean: ~0.849, median: ~0.848).\n",
        "\n",
        "- Lý do: KNN Imputer tận dụng được mối quan hệ giữa các đặc trưng để ước lượng giá trị thiếu chính xác hơn, trong khi Simple Imputer chỉ dùng giá trị trung bình/trung vị → mất thông tin.\n",
        "\n",
        "*Ảnh hưởng của số chiều PCA*\n",
        "\n",
        "- PCA=12: Accuracy ~0.862.\n",
        "\n",
        "- PCA=8: Accuracy giảm còn ~0.855.\n",
        "\n",
        "- Kết luận: Logistic Regression cần giữ lại nhiều chiều (12) để không mất thông tin quan trọng, do LR là mô hình tuyến tính, khá nhạy cảm với việc mất biến.\n",
        "\n",
        "*So sánh Standard Scaler và MinMax Scaler*\n",
        "\n",
        "- Standard Scaler kết hợp KNN Imputer cho kết quả tốt nhất.\n",
        "\n",
        "- MinMax Scaler (range 0–1 hoặc 0–10) có kết quả tương đương (~0.854), không vượt trội.\n",
        "\n",
        "- Lý do: Mô hình phù hợp với scale của standard scaler hơn do scaler này “cân bằng” dữ liệu quanh 0, hỗ trợ tốt cho thuật toán tối ưu.\n",
        "\n",
        "*Kết luận cho LR:*\n",
        "\n",
        "- KNN Imputer (n=5) + Standard Scaler + PCA=12 là cấu hình tối ưu.\n",
        "\n",
        "- Đạt Accuracy ~0.862, F1-score ~0.862.\n",
        "\n",
        "**2. Support Vector Classifier (SVC)**\n",
        "\n",
        "*So sánh KNN Imputer và Simple Imputer*\n",
        "\n",
        "- KNN Imputer với n_neighbors=10, Standard Scaler, PCA=12 đạt Accuracy ~0.875, tốt hơn hẳn Simple Imputer (~0.860).\n",
        "\n",
        "- Giống như LR, KNN Imputer giúp dữ liệu đầu vào “mượt” hơn, hỗ trợ SVC tìm được siêu phẳng phân tách tốt hơn.\n",
        "\n",
        "*Ảnh hưởng của số chiều PCA*\n",
        "\n",
        "- PCA=12: Accuracy ~0.872–0.875.\n",
        "\n",
        "- PCA=8: Accuracy giảm còn ~0.860.\n",
        "\n",
        "- Giữ nhiều chiều (12) cho phép SVC tận dụng tối đa thông tin để phân lớp.\n",
        "\n",
        "*So sánh Standard Scaler và MinMax Scaler*\n",
        "\n",
        "- Standard Scaler cho kết quả tốt hơn và ổn định hơn.\n",
        "\n",
        "- MinMax Scaler với range rộng (0–10) có kết quả khả quan (~0.863), nhưng vẫn kém so với Standard Scaler.\n",
        "\n",
        "- Lý do: SVC (kernel RBF/linear) hoạt động hiệu quả hơn khi dữ liệu được chuẩn hóa về phân phối chuẩn.\n",
        "\n",
        "*Kết luận cho SVC:*\n",
        "\n",
        "- KNN Imputer (n=10) + Standard Scaler + PCA=12 là cấu hình tối ưu.\n",
        "\n",
        "- Đạt Accuracy ~0.875, F1-score ~0.874.\n",
        "\n",
        "**3. Random Forest (RF)**\n",
        "\n",
        "*So sánh KNN Imputer và Simple Imputer*\n",
        "\n",
        "- Với KNN Imputer (n=5 hoặc 10), Standard Scaler, PCA=12: Accuracy ~0.877.\n",
        "\n",
        "- Simple Imputer kém hơn (mean ~0.869, median ~0.874).\n",
        "\n",
        "- Tuy nhiên, mức chênh lệch không quá lớn vì Random Forest vốn đã robust với dữ liệu thiếu, nhưng KNN Imputer vẫn giúp cải thiện nhẹ.\n",
        "\n",
        "*Ảnh hưởng của số chiều PCA*\n",
        "\n",
        "- PCA=12: Accuracy ~0.877.\n",
        "\n",
        "- PCA=8: Accuracy giảm xuống ~0.862.\n",
        "\n",
        "- Giữ 12 chiều cho phép RF khai thác được nhiều đặc trưng hơn, phù hợp với bản chất cây quyết định vốn chia tách mạnh theo nhiều biến.\n",
        "\n",
        "*So sánh Standard Scaler và MinMax Scaler*\n",
        "\n",
        "- Với RF, scaler ít ảnh hưởng hơn vì mô hình dựa trên ngưỡng chia (tree-based).\n",
        "\n",
        "- Tuy nhiên, Standard Scaler + PCA=12 vẫn cho kết quả nhỉnh hơn.\n",
        "\n",
        "*Kết luận cho RF:*\n",
        "\n",
        "- KNN Imputer (n=5 hoặc 10) + Standard Scaler + PCA=12 là cấu hình tối ưu.\n",
        "\n",
        "- Đạt Accuracy ~0.877, F1-score ~0.877, cao nhất trong các mô hình.\n",
        "\n",
        "**4. Tổng kết và lựa chọn cuối cùng**\n",
        "\n",
        "- Imputer: KNN Imputer vượt trội hơn Simple Imputer cho cả 3 mô hình.\n",
        "\n",
        "- Scaler: Standard Scaler nhìn chung phù hợp nhất, đặc biệt với LR và SVC. Với RF, scaler ít ảnh hưởng.\n",
        "\n",
        "- PCA: PCA giữ lại các thành phần chính để giải thích, giữ lại 12 chiều là tối ưu do nó giữ được nhiều thành phần chính và loại bỏ những thành phần dư thừa\n",
        "\n",
        "**So sánh mô hình:**\n",
        "\n",
        "- Logistic Regression: Accuracy ~0.862 (tốt nhưng thấp hơn SVC, RF).\n",
        "\n",
        "- SVC: Accuracy ~0.875 (ổn định, tốt hơn LR).\n",
        "\n",
        "- Random Forest: Accuracy ~0.877 (cao nhất, ổn định nhất).\n",
        "\n",
        "**Kết luận cuối cùng:**\n",
        "\n",
        "- Với tập dữ liệu trên và với các mô hình SVC, LogisticRegressios và Random Forest thì mô hình Random Forest với KNN Imputer (n=5 hoặc 10), Standard Scaler và PCA=12 là mô hình tối ưu nhất, đạt Accuracy ~87.7% và F1-score ~0.877. Vì thế đây là mô hình tối ưu nhất trong các mô hình mà nhóm thử nghiệm."
      ],
      "metadata": {
        "id": "lyDxb0BAOscH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}